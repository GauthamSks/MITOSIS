{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T3wsPASM-pv",
        "outputId": "701dbfd4-262a-4181-cf4c-89f77bcf98eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcp59hiK6w5S",
        "outputId": "e99c40e7-9d21-42ee-a41a-4cf6d58cbec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.6+cu111)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.63.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.9)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.1)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (21.4b2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.5.post20220305)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n",
            "Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (2022.3.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.4.3)\n",
            "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.5)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (4.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9RnH1uv67GW"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "\n",
        "# Setup detectron2 logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y39gRd3EQw8e",
        "outputId": "bd84a17c-17ec-4e36-d320-4b476403bdbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   887  100   887    0     0   1825      0 --:--:-- --:--:-- --:--:--  1821\n",
            "100 45.6M  100 45.6M    0     0  51.5M      0 --:--:-- --:--:-- --:--:-- 51.5M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/A00_00_bmp_jpg.rf.1ea980a7e2c95288e0fb2943975ad14e.jpg  \n",
            " extracting: test/A00_00_bmp_jpg.rf.3f0408d1e7637b1db780e7388effc433.jpg  \n",
            " extracting: test/A00_00_bmp_jpg.rf.5b6e263c867e9695556755c7fee765f8.jpg  \n",
            " extracting: test/A00_00_bmp_jpg.rf.8e6d38741a15c3a9b335dc4799a15221.jpg  \n",
            " extracting: test/A00_00_bmp_jpg.rf.c251c869ab047f762f1f01468a370cee.jpg  \n",
            " extracting: test/A00_08_bmp_jpg.rf.48e718e06371696548670065f72111c4.jpg  \n",
            " extracting: test/A00_08_bmp_jpg.rf.e3e4ae3adcc0095cea53cc8b60f4a812.jpg  \n",
            " extracting: test/A01_04_bmp_jpg.rf.02ab096a889ae325c3866f4719f5ce4d.jpg  \n",
            " extracting: test/A01_04_bmp_jpg.rf.310ac9bf452a03f53ee505b6aa9f6f6d.jpg  \n",
            " extracting: test/A01_04_bmp_jpg.rf.49bd1655d7486f78079f96db2ddf8fd4.jpg  \n",
            " extracting: test/A01_04_bmp_jpg.rf.4fd191cf440c4b39828240840f5dbbe8.jpg  \n",
            " extracting: test/A01_04_bmp_jpg.rf.52a3e18443e9d124fe3a3e327456b2e1.jpg  \n",
            " extracting: test/A01_04_bmp_jpg.rf.5df2952cfdcb5455825c5fb8be053574.jpg  \n",
            " extracting: test/A01_06_bmp_jpg.rf.2e9cb983e2db2901c6b8a33a8ab308f6.jpg  \n",
            " extracting: test/A01_06_bmp_jpg.rf.4e2c45ca6dedf2a48ca58573d55343a0.jpg  \n",
            " extracting: test/A01_06_bmp_jpg.rf.aa3d6750817af1ddb5406240a756a282.jpg  \n",
            " extracting: test/A01_09_bmp_jpg.rf.065fff458c326f643d09951ab51caeb0.jpg  \n",
            " extracting: test/A01_09_bmp_jpg.rf.2fd7ee2ecc0ff70e73222dccfbcce300.jpg  \n",
            " extracting: test/A01_09_bmp_jpg.rf.712e8706d15fd01dde068d8982946f27.jpg  \n",
            " extracting: test/A01_09_bmp_jpg.rf.819c2a3b6a7b747ceaa4ad5634af59d1.jpg  \n",
            " extracting: test/A01_09_bmp_jpg.rf.8eb3d6633b2a8a43b674875ac40f47ff.jpg  \n",
            " extracting: test/A01_09_bmp_jpg.rf.b3d555061c3a961910032a6a01d2a21c.jpg  \n",
            " extracting: test/A01_09_bmp_jpg.rf.f1ac882ab8f0d8773c72f0c9d7ec1200.jpg  \n",
            " extracting: test/A02_00_bmp_jpg.rf.7e55a32df1b02f74d4880fc55c5022dc.jpg  \n",
            " extracting: test/A02_00_bmp_jpg.rf.bbb74d7e7b952b72057f04bc881dd205.jpg  \n",
            " extracting: test/A02_00_bmp_jpg.rf.c1faf307dcb429aaedd65ced60dcf4a9.jpg  \n",
            " extracting: test/A02_01_bmp_jpg.rf.257046285b519e6d8413176958b402c9.jpg  \n",
            " extracting: test/A02_01_bmp_jpg.rf.ef4ed83e69e9f8f2dcf7cd208b935325.jpg  \n",
            " extracting: test/A02_03_bmp_jpg.rf.61b475bbbc405a5c3df2c0b866296299.jpg  \n",
            " extracting: test/A02_07_bmp_jpg.rf.11841b6024264a58756ee075e53c4d9c.jpg  \n",
            " extracting: test/A02_07_bmp_jpg.rf.2f36c618dc38d8ad2ee5415fe1480ca3.jpg  \n",
            " extracting: test/A02_07_bmp_jpg.rf.6bc01c0afdc5896c40f76c71e9161333.jpg  \n",
            " extracting: test/A02_07_bmp_jpg.rf.8fa063ff1b1dde920e1ad08adea421b4.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.0150b6f20a0038409f2b23d7c21374da.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.0d761dd694294d767d0fb80221e0dc24.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.167facf463e84227ec766935e547699b.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.187b6dab3b07a4986279ca8c7d9893c0.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.35291da875d74c9adf1dccf926f870e4.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.6e8de0ca78b52e597d8763c84cbe3a6e.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.8e86b36864c36e16b04ffe8819da82f7.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.a9b3786bb3b1e5f5a27beaa42fcc0927.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.c7d09fb8a4b2a84b9a251a555863e9f9.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.c9d672fa0a3c63dbc41327c8fa2b3077.jpg  \n",
            " extracting: test/A03_00_bmp_jpg.rf.d78fbaa7d2853907946f109893ded2e2.jpg  \n",
            " extracting: test/A03_01_bmp_jpg.rf.07ec5aba5332b13c59466b52aab94504.jpg  \n",
            " extracting: test/A03_01_bmp_jpg.rf.1726706a8015cb34a408d4b5527cd6ed.jpg  \n",
            " extracting: test/A03_01_bmp_jpg.rf.20882e68cc7041fa3ee006fcacb40304.jpg  \n",
            " extracting: test/A03_01_bmp_jpg.rf.20c90a45752ba065402a8df8932fd5ac.jpg  \n",
            " extracting: test/A03_01_bmp_jpg.rf.473e90e952fba3d370b17c4e7d99c58a.jpg  \n",
            " extracting: test/A03_01_bmp_jpg.rf.f21472756c8895ad8e127864f5452875.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.15ff8885f294cea2fa7cf69659ffb68c.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.307b2225a6b4679e90aa9e47c36cc975.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.7f67f2a9ba2d6533ca4a5dd81efd39fa.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.83f9205bd4a498dbd94db01339476bd9.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.9330594ac6cf6aafffa61766664c7194.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.9e463618840403b5717fcdb274906b75.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.abb9c07daa11dfe6ebe2810a70df7c53.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.bf3a5bc1a8be5ebd9c2bf74550847a21.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.c16eb07c4a15f28e2485ed2ab0b53bf4.jpg  \n",
            " extracting: test/A03_04_bmp_jpg.rf.cc5c202a4d6238f79a54d5e23f64300c.jpg  \n",
            " extracting: test/A04_03_bmp_jpg.rf.0b725c032186b3bd76863ce9dea47f08.jpg  \n",
            " extracting: test/A04_03_bmp_jpg.rf.2718452558150a51fec577ca25382624.jpg  \n",
            " extracting: test/A04_03_bmp_jpg.rf.2c4ce3d27415c8d8907f920099a5ac2a.jpg  \n",
            " extracting: test/A04_03_bmp_jpg.rf.804df9309f7c8bc8c7111f965f918a0e.jpg  \n",
            " extracting: test/A04_03_bmp_jpg.rf.a172926fc797fff3cf9f0e17955919e9.jpg  \n",
            " extracting: test/A04_03_bmp_jpg.rf.b7104bc2f6eea134e9d15cdb22e85df2.jpg  \n",
            " extracting: test/A04_03_bmp_jpg.rf.fc2e67e0ab80e1b02c5c3ca321f2c932.jpg  \n",
            " extracting: test/A04_07_bmp_jpg.rf.070d674a38f8a5784e140f0ec3f44c71.jpg  \n",
            " extracting: test/A04_07_bmp_jpg.rf.2d6abdd4fae777ccd7d79086a0901561.jpg  \n",
            " extracting: test/A04_07_bmp_jpg.rf.843428e4d1af5abdf1b7b7c6219c5fe3.jpg  \n",
            " extracting: test/A04_07_bmp_jpg.rf.b366e838c4fa207c511d33d827429a77.jpg  \n",
            " extracting: test/A04_07_bmp_jpg.rf.db3b529c2e2b7217a2fbb71fd4497a4a.jpg  \n",
            " extracting: test/A04_09_bmp_jpg.rf.33c047cee51866b564e160a78db85a0f.jpg  \n",
            " extracting: test/A04_09_bmp_jpg.rf.a181e051a525500e50d7f1a42cc7f261.jpg  \n",
            " extracting: test/A04_09_bmp_jpg.rf.a5f07879e61623d380985a54e8fa9daa.jpg  \n",
            " extracting: test/A04_09_bmp_jpg.rf.bdca050a3867c9310aaf33d6303282a2.jpg  \n",
            " extracting: test/H00_00_bmp_jpg.rf.63b072e95bc6d7e13c220bd0b31e6073.jpg  \n",
            " extracting: test/H00_00_bmp_jpg.rf.881536dd5987df2a90974fe11be6a8b0.jpg  \n",
            " extracting: test/H00_00_bmp_jpg.rf.c0f30a7f991382550aa5c171e99c57ce.jpg  \n",
            " extracting: test/H00_00_bmp_jpg.rf.e2797040f6d74a8181a9b29e013da679.jpg  \n",
            " extracting: test/H00_00_bmp_jpg.rf.e5237e86d458a138b688943a3228603f.jpg  \n",
            " extracting: test/H00_08_bmp_jpg.rf.9fa3a96148b082be46c399e01b34c0f7.jpg  \n",
            " extracting: test/H00_08_bmp_jpg.rf.f63d898d875c8d2a41336da0e18dc90a.jpg  \n",
            " extracting: test/H01_04_bmp_jpg.rf.398f794cd6137beffb9da9afa611aee7.jpg  \n",
            " extracting: test/H01_04_bmp_jpg.rf.4e63aa7e52c9773975467bd4ea4f4d08.jpg  \n",
            " extracting: test/H01_04_bmp_jpg.rf.54466a7cec3d2f17cc027c4cc7e2769e.jpg  \n",
            " extracting: test/H01_04_bmp_jpg.rf.62fbc2ae8812020691154ca9e9e4fa54.jpg  \n",
            " extracting: test/H01_04_bmp_jpg.rf.d7787c7924aec2a7ce86ada17239dc8f.jpg  \n",
            " extracting: test/H01_04_bmp_jpg.rf.d8966acae80226396857e744bba15ce4.jpg  \n",
            " extracting: test/H01_06_bmp_jpg.rf.1dc8b11bb699d2db51c191b033a0dbea.jpg  \n",
            " extracting: test/H01_06_bmp_jpg.rf.609d9e5dc8d4d5948c2f4ce9b6a57479.jpg  \n",
            " extracting: test/H01_06_bmp_jpg.rf.93175ec4a13c1f4f7ea21a119a2e5168.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.25418dd2c33ff5fcccc1a61008c44d20.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.2d104df5cab09b2669191db6e5b245c3.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.322146b922ac42bd8aa451705bac60c6.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.38b093c7aa9d1103ced17526dacf0fef.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.3c018d20ccef922b4883aedca510167f.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.52ec586dd2835455d17bb41ab11a2846.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.f89c9f7c70ee4d7a8c734e94f531fa74.jpg  \n",
            " extracting: test/H01_09_bmp_jpg.rf.fa3ed96c7fc203885c30aa337b315cd5.jpg  \n",
            " extracting: test/H02_00_bmp_jpg.rf.bc4612bc87d0aca7d31b54f8035a1ef7.jpg  \n",
            " extracting: test/H02_00_bmp_jpg.rf.ee2dc78136894d63b7daa49833c999e1.jpg  \n",
            " extracting: test/H02_00_bmp_jpg.rf.fdf68aacc975c153b693c87e5323fd5c.jpg  \n",
            " extracting: test/H02_01_bmp_jpg.rf.9e9f77470847260976f298638139f799.jpg  \n",
            " extracting: test/H02_01_bmp_jpg.rf.ef78392f4a9dd165d2e11337c3fa6cf5.jpg  \n",
            " extracting: test/H02_03_bmp_jpg.rf.adce72c2021d18ac75b2fe38b2dd224b.jpg  \n",
            " extracting: test/H02_07_bmp_jpg.rf.4d7930cc60ee357b62bb6b30d691cfdb.jpg  \n",
            " extracting: test/H02_07_bmp_jpg.rf.a008aa45add8e11f715bcd854dea74a1.jpg  \n",
            " extracting: test/H02_07_bmp_jpg.rf.b559239b9013f200f503c54c605950da.jpg  \n",
            " extracting: test/H02_07_bmp_jpg.rf.d719aaf8739344bf0bb900792a0cbfd1.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.26dc8d66dc13d010d483e4ccf4df8e58.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.3c6d85bbcfd4fc8f15d852b8806672bd.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.62fbeb4819e7b5f9b851c36bf4267bfd.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.65f340a21c33194a0bcaae070ac3e64f.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.73e2acfc0181b2615d5d2d6015bcf0d9.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.77a8a3497b60a87322ee57fa5aabbd9c.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.88126992c668110b4b752c9cd172e14a.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.b6ba5bab4a523ad5885bc193896a86d6.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.ba31307c99f159c18a983c85c3ca6ab1.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.e19a498d83736a8baa2d570b6b56dbca.jpg  \n",
            " extracting: test/H03_00_bmp_jpg.rf.f0d207960bcd296a4656a472f5c8f3e1.jpg  \n",
            " extracting: test/H03_01_bmp_jpg.rf.0da7746e64d90de66e5d16f8ea4d28ef.jpg  \n",
            " extracting: test/H03_01_bmp_jpg.rf.8450c547d3980b86b0b6932a9288b7ae.jpg  \n",
            " extracting: test/H03_01_bmp_jpg.rf.ac48fd83f3b6db5444c48a6b463cd746.jpg  \n",
            " extracting: test/H03_01_bmp_jpg.rf.acc77a545f94b1cfc4102af2c65daa2b.jpg  \n",
            " extracting: test/H03_01_bmp_jpg.rf.aefb76aa04365c27e8e98034b7db0af4.jpg  \n",
            " extracting: test/H03_01_bmp_jpg.rf.b3a341eceb48a310c4ddb7f8c35805f7.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.2713b48b6c0d30ae35b8bc5b1e8e5b1a.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.495dc8ef05af902ba04523f6d58601eb.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.8f0a6e86bef2767024d64e8fe4eeeda9.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.98c53531ff9a3d08781b73ecc4c8e668.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.9cb18b37ec49f672bb34fa168cafff6a.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.c6a77fa6ac199440ddfe3dff32e2ee0f.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.f1db83da39a5f0bfbcffe699cea4330c.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.f27f3dc2ff426b0adaf4f5061b25fc42.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.f625af87ba6d3368c1a2a22d1360499a.jpg  \n",
            " extracting: test/H03_04_bmp_jpg.rf.feb02bfb1f5e33c09896cf312e540c38.jpg  \n",
            " extracting: test/H04_03_bmp_jpg.rf.01b498adff179b0944c32134f804a57d.jpg  \n",
            " extracting: test/H04_03_bmp_jpg.rf.022a15e4ee2a230e953d8fa995da2a44.jpg  \n",
            " extracting: test/H04_03_bmp_jpg.rf.477bbddd99686bcfc6a840d4420b4e83.jpg  \n",
            " extracting: test/H04_03_bmp_jpg.rf.5c0751d2b0f0120ddbd57abc981d0bda.jpg  \n",
            " extracting: test/H04_03_bmp_jpg.rf.610bc665862cc680fc82530db4765a72.jpg  \n",
            " extracting: test/H04_03_bmp_jpg.rf.8c60b8746fd6ac9fdcf0fa56ac84a0f9.jpg  \n",
            " extracting: test/H04_03_bmp_jpg.rf.9ff61b0b92bdab147adecd6a49988933.jpg  \n",
            " extracting: test/H04_07_bmp_jpg.rf.091654b23a6f371423c0b5ff3b2f89f0.jpg  \n",
            " extracting: test/H04_07_bmp_jpg.rf.7970c0711f3521054e3f7ff7e92786c6.jpg  \n",
            " extracting: test/H04_07_bmp_jpg.rf.8430b4a4f6d2ff98b937e3e275a6221b.jpg  \n",
            " extracting: test/H04_07_bmp_jpg.rf.eba6c5182239727e5f91d584d30aec85.jpg  \n",
            " extracting: test/H04_07_bmp_jpg.rf.ffc8d963702c9225876c00c3f27b502d.jpg  \n",
            " extracting: test/H04_09_bmp_jpg.rf.0985f64c7341f7fe4bcd823c75a8da57.jpg  \n",
            " extracting: test/H04_09_bmp_jpg.rf.43b3ab8acf3098dafc7ad168a74564bc.jpg  \n",
            " extracting: test/H04_09_bmp_jpg.rf.5bc6a21ab485a2814256918b85ba0df0.jpg  \n",
            " extracting: test/H04_09_bmp_jpg.rf.7e914fdda3a2378a92b884e4d3c91732.jpg  \n",
            " extracting: test/_annotations.coco.json  \n",
            "   creating: train/\n",
            " extracting: train/A00_01_bmp_jpg.rf.040d705dea11c313e24e4719b7314941.jpg  \n",
            " extracting: train/A00_01_bmp_jpg.rf.56a602576c3793111167ba0044d25816.jpg  \n",
            " extracting: train/A00_01_bmp_jpg.rf.65284053ed1c4e6fcf3b7a0648141264.jpg  \n",
            " extracting: train/A00_01_bmp_jpg.rf.bd388b1e79bb87f953602e5bf5cae391.jpg  \n",
            " extracting: train/A00_01_bmp_jpg.rf.c6c8ef38064780b75c5723310e3015aa.jpg  \n",
            " extracting: train/A00_02_bmp_jpg.rf.0dd33c5ad548f273d02d778b5445db83.jpg  \n",
            " extracting: train/A00_02_bmp_jpg.rf.22cbb5c1df16b458a602d7c3d3652e82.jpg  \n",
            " extracting: train/A00_03_bmp_jpg.rf.0fd52b40a33bcb8cf352fe97f60231a1.jpg  \n",
            " extracting: train/A00_03_bmp_jpg.rf.32cdaaee2d346249a66a13aa7495a59f.jpg  \n",
            " extracting: train/A00_03_bmp_jpg.rf.adb65ad649813a579f260bd84f94b7d6.jpg  \n",
            " extracting: train/A00_03_bmp_jpg.rf.aeeb421bafa3c3c1cba50f9ee84b8c7f.jpg  \n",
            " extracting: train/A00_04_bmp_jpg.rf.00cafd36c66cff82daff85873f1673e1.jpg  \n",
            " extracting: train/A00_04_bmp_jpg.rf.1dbe0c3a66b64efad50c41e78a7a6684.jpg  \n",
            " extracting: train/A00_04_bmp_jpg.rf.539c6e8e4d4be9af78517851fba73561.jpg  \n",
            " extracting: train/A00_04_bmp_jpg.rf.568b183f5f35283773f3f4cfffd3dedd.jpg  \n",
            " extracting: train/A00_04_bmp_jpg.rf.abba5f7ab56732cb0626851e879e8982.jpg  \n",
            " extracting: train/A00_04_bmp_jpg.rf.c5065b8885b3dd9b602368224d9cef52.jpg  \n",
            " extracting: train/A00_05_bmp_jpg.rf.04ed6429eb1ac984f9742c3cbcabc375.jpg  \n",
            " extracting: train/A00_05_bmp_jpg.rf.86f2a2e1766d4ff352d6b70653d43459.jpg  \n",
            " extracting: train/A00_06_bmp_jpg.rf.33cfc7c01c334a93950781b041dd147f.jpg  \n",
            " extracting: train/A00_06_bmp_jpg.rf.ac2a2e8ce876c8a59112b9815d9af5aa.jpg  \n",
            " extracting: train/A00_06_bmp_jpg.rf.b12c4941031e1bf2bcba08130bb0d731.jpg  \n",
            " extracting: train/A00_06_bmp_jpg.rf.db3a1c9bdd9ec27e22d1af79a28e4f97.jpg  \n",
            " extracting: train/A00_07_bmp_jpg.rf.6ec75db639c291f7d2c71d49035bbbcf.jpg  \n",
            " extracting: train/A00_09_bmp_jpg.rf.48438c783610c7dd98d1e42f9e43c408.jpg  \n",
            " extracting: train/A00_09_bmp_jpg.rf.488c120518a7f08d221a392f78d07cc9.jpg  \n",
            " extracting: train/A00_09_bmp_jpg.rf.6b0a82cf1bd345613f150e85e880bac9.jpg  \n",
            " extracting: train/A00_09_bmp_jpg.rf.d6e84a800f054e285bf562e08623d206.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.011ae51b955b7d1be0b512d0d9271357.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.29e4fb6a849e49b4790ec63556ee83e1.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.69d90d51121971e6b798711520c3d0ca.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.6f99f9cc337e31c99e174e19638ec885.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.80d0de20c54836f56fdce4e3bd248175.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.93bb7817f43f47cc6cccdd97773db14f.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.9e031e4f24f541640b9e08452d5021f0.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.9e4a6e3021a9255ded198faf67792545.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.af0bc599cd1dca9286750e410b772b14.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.c3bb7f7eaae93c6f2c55441687d5c5c8.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.e1e0efb08e05a5e3dcfc1337ccb2d624.jpg  \n",
            " extracting: train/A01_00_bmp_jpg.rf.f6d66a1bf1a7fee31130bbc10a9a0e2c.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.22ca98040a48c4d048f660c1753c6e04.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.9950f2dfa09d41ce3610720790dbfb4d.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.b2ec1bc5cad02136b08f5455b1ddbc45.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.ce7af848dcb287d3e0a86e98e5e7a7fa.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.d43818e9cb20bdc4b3591226c493265a.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.e1f77f231123c3980ffccea6deacf20e.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.f211c99fc9e97f54721876a64060c923.jpg  \n",
            " extracting: train/A01_01_bmp_jpg.rf.ff5d0e5c09f0d9c52f929d58889bc726.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.05e7d492d98d32277d958040083125d1.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.12da85eb0fbd9658f15b12355f4e9bd9.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.157724285a4dc8c85fc96c0a132a3a4c.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.1cdc3de7754d03fa6c00889ca7039492.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.414e3947d91e686e2ed8e6f319f5f7e8.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.52e799116e441c4392343aebaff7e42c.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.6915cbb72ec6344b19ff38786af99f86.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.7339ff9d4ce31bab85df7335a962b0c6.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.7a20c43fcdbdc0a66aa7b59791e04c21.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.7b681e82cfdc4e1a25162354c60c3e64.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.8734189bcd9d261a063bbda460b57823.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.afc9d54d4a1ea13b384a031d4979bdbb.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.eaa56f52dd5d35e59d667b667abe9a31.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.f7f5b9af91dc46790cf717d15212a686.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.f8197d573ce2758854d51ce486a31dc5.jpg  \n",
            " extracting: train/A01_02_bmp_jpg.rf.f9a98b6642a54eb2139cafdc3989681a.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.0f0ae8b2c4c8c0c45110270fc7877b4f.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.242981fbee8ebb1cd4bd5e1c291d3bec.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.2bb8a9e3012f590c699b3907542080fe.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.300bf769a57db0e2e5823886921f900d.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.33ba8750857cd241b58dc093d4242854.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.5a4901387b036381ddf0e84b0404f9dd.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.75d15e763c70b44e9e8fa7e6e623b021.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.7ad78476b4d3315daf8ad75b35ee310a.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.85894e3cd4791c5f26ce534a182e8355.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.8a346a397503f944d6f653c2b698f094.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.8eb4055b4298861ca1d1aa85625ab4c9.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.944c96d10bb9202aee2713c4e6fb94b2.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.a16dced5e06738d6ed58ea469b4e7f72.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.b459075af1fbdce21cdea63c3e7d5086.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.f11c692b33d3ba25f170db49c53f141a.jpg  \n",
            " extracting: train/A01_03_bmp_jpg.rf.fb7bca94d3cbb2a500818ea2011aa793.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.0355f2e4192ee47cbbdde43c6c69c4a1.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.519e23b8ad3cbe56a3814d344df7fc6a.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.56685a4433644f0e241ccae4f1526b62.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.5963191949bb2024f8f56a2bdc67059f.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.66e2ba131040b78964cb8b80e9a0bf71.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.82df382e9e764764ef58d40e63e79e38.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.cc1a37f9dab0c52f05f89ab5954a0f3c.jpg  \n",
            " extracting: train/A01_05_bmp_jpg.rf.f09770ae79d1c5372dd376d3a560fd3c.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.01a06df9f55a9a1bcf97aff4d3415ac5.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.1ab4a76cec7a7b2d0184bff11211d408.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.1da23084134c85157069d40bee051743.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.2b7dd49633b65d922590c512e73a604d.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.3a7e593b4046ac374e5496844d734427.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.3e2b4af5d397c7ad6124d91bc467f33f.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.43f8cbf890f01620b5b877734e60809e.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.5bf69ed4dcdd8517decd7666a79a6111.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.73f242a0891ee106624dbcc59b7b96e8.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.77ca519b205d2eaa4a7690fc7dbdffa5.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.ad9d12ef0b40f3e634ff624a9fa3fbdc.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.b4502dd1d7619aa30477dbd67642ef91.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.c65bc7b9964728cc20c4f88d642a7711.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.da512cb73c71fb7fc130a91d33765ecf.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.f5651c4463ca609fcf637901a7d8dd00.jpg  \n",
            " extracting: train/A01_07_bmp_jpg.rf.f61e4239a152045bb55866b5daae08e1.jpg  \n",
            " extracting: train/A01_08_bmp_jpg.rf.2adea960227afd1bda44657269dc3fdc.jpg  \n",
            " extracting: train/A01_08_bmp_jpg.rf.387d151d97947889ee5ad881966add9a.jpg  \n",
            " extracting: train/A01_08_bmp_jpg.rf.668dfae1dd234433473e0b82aff932b4.jpg  \n",
            " extracting: train/A01_08_bmp_jpg.rf.84523b9978efdc48c442d135d5636843.jpg  \n",
            " extracting: train/A01_08_bmp_jpg.rf.c5d4b6c1a40678b875b51639186c8b20.jpg  \n",
            " extracting: train/A01_08_bmp_jpg.rf.ee0957b8c0277a87d9fed497b161248e.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.28f760a2b699c37ed56e93eba3b2594d.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.31b313f5121a71bacb5b6c3d0a30cbed.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.33f7e676cd0786f3ae52f309185317e6.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.379523e6103fbca81fa6dd8a9d65d0e8.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.7588ea6aee3df7d9725eaf410690476f.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.9c56fc15197774a576c93864ab54130c.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.e4ca1ee1ab10fd4be06fb48ff63fa993.jpg  \n",
            " extracting: train/A02_02_bmp_jpg.rf.fc57037b262c8486b3896f938bd92c5e.jpg  \n",
            " extracting: train/A02_04_bmp_jpg.rf.0348a6b90df41991763e49de15538a02.jpg  \n",
            " extracting: train/A02_04_bmp_jpg.rf.0d2e779c736607c6aa569352808a704e.jpg  \n",
            " extracting: train/A02_04_bmp_jpg.rf.f28c9613773840569baffb1b78fcfb7e.jpg  \n",
            " extracting: train/A02_05_bmp_jpg.rf.3794003009fa9d770f2d599927d912ee.jpg  \n",
            " extracting: train/A02_05_bmp_jpg.rf.4d43a4b0d76bc7648d92e4a6945e3f49.jpg  \n",
            " extracting: train/A02_05_bmp_jpg.rf.8ee24ba9e30a62b2b72b39386a62b325.jpg  \n",
            " extracting: train/A02_06_bmp_jpg.rf.297c5d31b4e3bc4b536de4c6af98c36c.jpg  \n",
            " extracting: train/A02_06_bmp_jpg.rf.82d94ead74e6ed535e39bee393b01977.jpg  \n",
            " extracting: train/A02_06_bmp_jpg.rf.cc5e63d8f71d4d1bd9969a683f6ed962.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.3cf88b515ffda2e21c39fa99eca00557.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.3d519ec182dd0ff3d0be74f07ae1473c.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.4dc0ba3054dad5a5149bb421b3d8dbca.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.540546e6e4f079b4daf337a662c2acca.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.9ebef2489c0a47a2f2aaf2f713282d7d.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.c12735905cf46301c153ead47bc758b1.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.c8870841f6505de2e98b0b89852c5c19.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.c8cc3310108a3baf7f70337a7d5a59e8.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.f8816e14225e52c47f9de50d199274b2.jpg  \n",
            " extracting: train/A02_08_bmp_jpg.rf.fa9a33f3c28d7d505d9329a07e062eea.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.0b28433071ef27ab1eb59ebee786ab89.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.2a602a363b2acd28d1411baf60a22231.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.34fd7bfdb19d732e5454401433546e8d.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.36e7c67cdeecc47d366af7dbf741e5a7.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.3ba2c658a37da2dfaedbb7d315aa1270.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.5cf1ed9a21962321ac56b958fe303afb.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.82d8ddf257e37cefc674a7d867d6dd3a.jpg  \n",
            " extracting: train/A02_09_bmp_jpg.rf.9c7a4a23945d28d6aba5a547f5796746.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.190153674ce8e9581345f49e16051f1c.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.20278808392ea376446cb43eeffb35f7.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.24cd1acf410b19178f6b24959bb3b7ce.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.308cb169296e5c40f04bce478178a903.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.4619f67b4ed516dc70f03063381f75ea.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.5ead8c2a6dee7eebb46834bb6f62f086.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.5f63622f4817722a90487abd0b5200e6.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.63027f7cbbbdbdc3f57c35ada5bea045.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.797eb15e8333292e29574369122fa276.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.7bbfa99afe1732e72513b761dc5e5584.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.8528a35e4c94f42088646a7ee3ddb3dd.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.880c1c1ebeeb534c8753bb7f27b639ba.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.abd32dc034369226c2ad34397d75fea9.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.b60fbe8a73ba4874406f293ac5726089.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.b989a2f4995b402d6eee1019fbb44469.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.bb1d59ea31380867a3f56c9fdf38cfae.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.bbdb89ab4e276b6bdee322af74303da2.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.cbaef7fe7904219407e3b32ca6936ca9.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.cf1415b6afecf7c85fa7ee657b8b21fc.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.ee3a85b77466bc355148f3e616f986d1.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.f0d6b2e9398941b3600d32cce56e7cad.jpg  \n",
            " extracting: train/A03_02_bmp_jpg.rf.ff8aa778eb5ab1555e11120eee2cc98c.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.0cd1b3d3801268dbd30e1fdd90e42764.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.0f76910509a1e03fc330f313acf4d9ed.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.1b6403014b45b33837f071a7bc8b7c51.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.55246e8d43c7c0a6835a7868176b4dac.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.57af17be0b63ad6acaaae9cc64ff658e.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.594c6c5b87a14cc3fa6bacde512bd76e.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.7024e96d752544008dcdde9d8c21006a.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.704059c43f8711ce5e0e4dbbfaa5e30b.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.7143489adb36e7166f551e0f72ea66e2.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.7862c692642ddb546cf821e10b5ee575.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.abcf46c5357508273321a978de6ccb78.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.ae3b78dc54adc81833a9a6840aab7ef4.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.b324453795736b75fa8c2a9b791fea64.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.cea2063ac541a7a646779f3c4013b51e.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.d416b27d5116b1ddfc87c78127eb4413.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.dc7af8868e1709d6f214a1b41dc12b21.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.dc92b39896a960d6daef66d79d2f0d1d.jpg  \n",
            " extracting: train/A03_03_bmp_jpg.rf.e3b2a106e757560a12dee21a75bc6449.jpg  \n",
            " extracting: train/A03_05_bmp_jpg.rf.08f1ff33cbf5364465443e5b95e3ef8a.jpg  \n",
            " extracting: train/A03_05_bmp_jpg.rf.26de01ee2d8b466b78819bbb5a3eaba1.jpg  \n",
            " extracting: train/A03_05_bmp_jpg.rf.60ef2e64ad2809895abe36ba772c759e.jpg  \n",
            " extracting: train/A03_05_bmp_jpg.rf.714b6ab463ff17dad667719c5d3a7466.jpg  \n",
            " extracting: train/A03_05_bmp_jpg.rf.997d9c7b7eef83a8a81771df620f164e.jpg  \n",
            " extracting: train/A03_05_bmp_jpg.rf.d7152f06b408f8615c734ecc9cd07e4d.jpg  \n",
            " extracting: train/A03_05_bmp_jpg.rf.f9063f2ea163808042e97e0494434667.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.163eed8a9488915a14f4b20da1bc0864.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.2ada95661f0516b8aefca518f6806bac.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.309fc130e8b30de4b43e2921e0d4f407.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.3c20ceb1e3b40ec777295adc5725c5c1.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.471ce02c7c7000309ba5774881e85c70.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.4eb2247ce799efe576584a187cf0da06.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.6d66d6c3844af84a18f23e118ad40896.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.7f6f0a4e08482f01502fd604852c5b7b.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.81a64ef47b0b7953f00a09d16bb4e971.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.825918e173fbefda5649527a67504e0f.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.90f422590ddb33416b57c551c17c48e8.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.92b91acf14d7c30a9765eb3ead51767f.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.a9cc3b560c2c991cf7bc338ed6c4e894.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.a9ccf500c512052d2183d61ab13a6824.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.b4abbdc08f25c193d2a3248660cf8daa.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.c85a921f296efce97cad8b5a9e803afc.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.f25d11464a6179cdffc75d98eddf7aa0.jpg  \n",
            " extracting: train/A03_06_bmp_jpg.rf.ff474d13b36bc9a77e5a87b48192754c.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.14293973e1b173c512832e2abfb4c994.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.30878491f10c04ee4c8e999ead97bcf6.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.4dd53473784e2a0bb22f1389adf23d54.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.5fb65bf14c0f928dfb5683bdbfc75d92.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.6a0f8aadf989f134b13d10c7dd5c7a66.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.6af16aadab2cdf6f0a9b5b525bf03ab9.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.8a08f254e4fa1198085b502d1855bba1.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.9f19165c8caffd3a522b66aa000b110a.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.be7b6029490969d9c40e89f8b96d386b.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.c5e767f3615f2ba31e4e7433824616b9.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.d56e0db0616ea516f8b86119021bab92.jpg  \n",
            " extracting: train/A03_07_bmp_jpg.rf.f1518fe7a5cb0a0d210f4a810006c3a2.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.06d0a5158f2ad457bd265233b9812b85.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.0c9330c76a92e47031144bf3a6a69d61.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.29af76029371bcceb5543ee8e795b906.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.2e53596960fc3c0e5e7d242197df598f.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.352007c3375414730cc82fce282750ec.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.3dd2a84418a70719360e1c5ba4c7dcd5.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.536f88b341293d32b3b6ebd02c3360bb.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.5dfc9a0de1a412dbb15d899b27ba2532.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.6d0f61cc7ca10cc4c73c983746b0fc3c.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.72e55b1920969a0e9b4b60b7913027bc.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.8823081cb7ae357338b9937958219040.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.cbf1ecb30ef17fb852d4b04d10a9d42f.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.cd228013a3990c955aaf72e0c4dd6e2b.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.e2c07d649d8108eb04afb655cf8b98f9.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.e303435e14881d5433593fbf1ac2f5c8.jpg  \n",
            " extracting: train/A03_08_bmp_jpg.rf.e4de735958f9ec0b34bc35a53a1f3677.jpg  \n",
            " extracting: train/A03_09_bmp_jpg.rf.1124c81e13d88a54f748155c1042f380.jpg  \n",
            " extracting: train/A03_09_bmp_jpg.rf.2e5b2348360b6ea51e25c89ecd0f9111.jpg  \n",
            " extracting: train/A03_09_bmp_jpg.rf.5b9612ef3fcc59b932a839397b44283a.jpg  \n",
            " extracting: train/A03_09_bmp_jpg.rf.c1def94036ba2e87f8e9b3918cbe0264.jpg  \n",
            " extracting: train/A03_09_bmp_jpg.rf.cf0886c867c9669f0706b5cff6754f68.jpg  \n",
            " extracting: train/A03_09_bmp_jpg.rf.e5d9d42cb38459abba9ad7c2cd6babf0.jpg  \n",
            " extracting: train/A04_00_bmp_jpg.rf.071e2420db4c7ea49719a39640a673a6.jpg  \n",
            " extracting: train/A04_00_bmp_jpg.rf.1010b507ed0e8a4e682686766cee3d37.jpg  \n",
            " extracting: train/A04_00_bmp_jpg.rf.a1727914c2a660ca64f0054404f9c5bb.jpg  \n",
            " extracting: train/A04_00_bmp_jpg.rf.f616e426b31d3a780649178a665462e2.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.13488154eab93a05286dbb91877afd19.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.27b6da16ac847bbfaa58b1e809c01466.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.3fb379af219618233906d2de6310810b.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.58061a5bab8507c8d66b7fca534af6c6.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.6695da7e73f4d904d19192b67287e40a.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.a4f3382d9b811da090f86523b64b6227.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.b6e35a8e330ebd6d673be1e5a1e80593.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.cf2b78c627ab9fa0727be3345f01492c.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.dc7f11712b4f8c4eb02cca1fdb08b8ac.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.ec3d163f9fb6ab6fa678817fb12830c5.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.eccacfa60a45f1b48cf85a03141c397f.jpg  \n",
            " extracting: train/A04_01_bmp_jpg.rf.fc6346d7ebe18c5686a274edd8f96d4e.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.3ed0986af4d50b0fa9c23ecb77e62422.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.60203cb443460198c25e49e30e027ee3.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.68cab16b542fb104d12cdfaa0871c43e.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.86ecaea2c92b14cf6dbe0b52ed156253.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.884ef82a777cc23b433de44e24ad7c54.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.8e10e48d4f429794ad0a39ef484549f2.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.d82bb2000cfdfc3158826ba2ca05b2b1.jpg  \n",
            " extracting: train/A04_02_bmp_jpg.rf.f02dbe15cc8271951da46362130ae96f.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.03ddf799cc5c1314211e2c22df6865fa.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.089ab22e615660a8bde348d5ed559c54.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.27915120f42773bbb0fd23b4bc83913d.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.35007e5b9afb5a914b8ce96596e69b00.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.3ad0e40acc65ce2a8feb076c81b8f65e.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.644d5e5259f07c6e7d610e2de7d041d2.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.7b70462b1c66fc3fabc07b28c4971e82.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.ac751fea8faf26925dd3ee559e52e5cb.jpg  \n",
            " extracting: train/A04_04_bmp_jpg.rf.c1d0b79b7ce6568d774b9a0d82dff25d.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.21fd151b31d2a4d643a50f89cec9a118.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.36571c3a0ac39308f0eb064bb5376b38.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.403ea3254f0bb4fa0cd1383dbd6cdc7b.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.417198221d1af23333926925551d43b0.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.49e71ca3f0da54b2488c6b52a6f46c03.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.5b1556accb6409e076d26607a4f216aa.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.650a85ec187974b6fec238e1533b49d5.jpg  \n",
            " extracting: train/A04_05_bmp_jpg.rf.9fc580d280a18b692889e8a4e2af6afb.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.19a55a5bb1a63ee2fa3f52177ceffa0d.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.33ac3476ddc97da49b6b80c591c9f75c.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.524cfc0bcc96c185a74948096b2592a2.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.5e8120a9d7d99924792f8eac04928241.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.75a6d81d07b00d4adad7046f901df114.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.8b62b3d43575b599374e6545a662669b.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.97bde64fe9989dbf4db649abaa0e0622.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.a90b54cd814f2057c3749a0f609630df.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.f2a4dcbd95dc27bfab3f2bb0baa5ab32.jpg  \n",
            " extracting: train/A04_06_bmp_jpg.rf.fcb285a0fdad164fca97a5abd2992bb2.jpg  \n",
            " extracting: train/A04_08_bmp_jpg.rf.1be6eccaf6bedc3c104ef30c26039425.jpg  \n",
            " extracting: train/A04_08_bmp_jpg.rf.3b95d66982563695f92d13dc090c7299.jpg  \n",
            " extracting: train/A04_08_bmp_jpg.rf.57bd074c46fd18f5c0675996a1b44eb8.jpg  \n",
            " extracting: train/A04_08_bmp_jpg.rf.93cf441e7c8d893127816b16c54fa1be.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.0fe660269dc21043ee24153ade4a5c45.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.1e7bf1d0420bb367d2f6f3a7f29d4d93.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.4fdd1ec72ac8e239c3360f4b895c4ba4.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.afc9394546ac50e6611a0846857462c7.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.b12c34c0dc776edd609765def902933d.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.b7496d8c69b19f26ac639fd8c657cdf8.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.c7c3ffdf6e8229aefbe0eb7b39f64db1.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.cd1efbf24985af2ee3448206239a47f1.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.e16bb3d3915dc9c303ac93c8760734d1.jpg  \n",
            " extracting: train/H00_01_bmp_jpg.rf.e1c8626f51dcd6b3bd78265b5c1e813e.jpg  \n",
            " extracting: train/H00_02_bmp_jpg.rf.4df6b8a768c71a03bf317f25328f6cbc.jpg  \n",
            " extracting: train/H00_02_bmp_jpg.rf.87be18e9080a012c5aa7c2280be2bad2.jpg  \n",
            " extracting: train/H00_02_bmp_jpg.rf.8cbfb0baea60c36c382238b7fa5a6f0c.jpg  \n",
            " extracting: train/H00_02_bmp_jpg.rf.ec2eb32698803b6353035cf1480aab39.jpg  \n",
            " extracting: train/H00_03_bmp_jpg.rf.1c2e3970380e55c0e2354e9940a1c265.jpg  \n",
            " extracting: train/H00_03_bmp_jpg.rf.c946741ca03138fdf814776adf92a622.jpg  \n",
            " extracting: train/H00_04_bmp_jpg.rf.1e1d4c9ae7202277acba60d4fb75e9c7.jpg  \n",
            " extracting: train/H00_04_bmp_jpg.rf.50273fd0542bbeb9ab838c27c70037ba.jpg  \n",
            " extracting: train/H00_04_bmp_jpg.rf.8b0dad6d2ee44c9846d9a7a4d1abda19.jpg  \n",
            " extracting: train/H00_04_bmp_jpg.rf.b444f19a20c16639847fcf753668f002.jpg  \n",
            " extracting: train/H00_04_bmp_jpg.rf.ccc6bc2be6714ba1412555f69f99b19c.jpg  \n",
            " extracting: train/H00_04_bmp_jpg.rf.f16ed68067c6116b6494dc93a02ba6e0.jpg  \n",
            " extracting: train/H00_05_bmp_jpg.rf.64fa14340bb3843a099284d82639d53f.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.1946eba2b0edf21b5919dd47109351de.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.1c72f7b5311a03fb3f02c29e354725d4.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.2199c50e9fbf9fd98a691660ac486d56.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.399d659f7f4b9acef65e0eec4f065438.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.3f47c6586260607a3a343711e83017b2.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.74b533785bb737b376bd907bc755792a.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.7c1d6736a5e165db838aa7a024f722ba.jpg  \n",
            " extracting: train/H00_06_bmp_jpg.rf.aeda3f159cd4a781967864704c5899db.jpg  \n",
            " extracting: train/H00_07_bmp_jpg.rf.08cf2e8885d725ad07cc150cd64f0dfe.jpg  \n",
            " extracting: train/H00_07_bmp_jpg.rf.f24655a16b7827c0e697a047a6f2009c.jpg  \n",
            " extracting: train/H00_09_bmp_jpg.rf.323a5b517146693751ae464e8df63735.jpg  \n",
            " extracting: train/H00_09_bmp_jpg.rf.5a7fc2db19f06d8b86eb25b8ce7812b9.jpg  \n",
            " extracting: train/H00_09_bmp_jpg.rf.97e3e74c3ac3fba5c613518a7c8a18e1.jpg  \n",
            " extracting: train/H00_09_bmp_jpg.rf.9c754e605bf8394874439971ce7a3025.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.3dad7af997d94313ba4836e29c16d99c.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.4e3cc31173a3fb8e75dd73f04e0e5755.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.81b2e3577d238ef84e3a1a5899f68d89.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.97e43be9851b6d4f0036744760d842b7.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.99958f9348fc992815854710e0450ec5.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.9b3a03851e069cef4ae5db4f0bf7070f.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.b318c1a44b33af5d2501d3a9faf245dc.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.b65d45775bbfb564b7221ff787470df3.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.bdf568f70ce4fc6edc34246871f503c2.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.c5445934d1d290d3f8713ceac4cfd88f.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.e0cd532722ed3e4d998b9b3226fdf7e0.jpg  \n",
            " extracting: train/H01_00_bmp_jpg.rf.fb43d5c04d5ecc4e65a4cec50b450ea9.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.8d7c5ab1e0fabf5724f9f119b46bbbc4.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.99f5fd057fcb4e8f24225d3b6bf673e3.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.a0eabe6e89454f7db2ab849daa70ee9f.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.a5d0ae0070cec57b0b63e02265cc0efc.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.af38a056b28d423f35d2951e0bc68a2b.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.b0223d92d2728c83c805e72c0d9d9701.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.ea568674c173ea0852adf632fad6d142.jpg  \n",
            " extracting: train/H01_01_bmp_jpg.rf.feb28418f22b43cd9c426ca3abb9d12a.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.0b49b466e0c429fa42cd4ad0d81f5f1d.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.25f5a4dafeb658f5cb8b6be411a70225.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.c17b139b473ea8ce793d3754b89d2ffe.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.da4842d393d72993327ffd8c8e22b50b.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.df69782c23e64161a18f3b11b9222a2a.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.ea40a4a95718432b12ee870e3fb86b98.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.f1f38a286c415016b3b78752dc7a21f3.jpg  \n",
            " extracting: train/H01_02_bmp_jpg.rf.f60bddfd5156fef1a9c8bf89dfd0d41e.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.3a027aa87549bff5ca54118a315d8b88.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.3b251ad36d51956198d8f0d4e9fdf1ff.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.794e36f6a55c1fe9dd5ad22b702c44b9.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.890dd32161b810e46992831e59488786.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.8b66ccbe972dbfa27c27a47e1fcf422b.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.a98cac0cfb6bf2cfb25e2ab43ca26267.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.d5b330c8f796682bd3aa301eef19d096.jpg  \n",
            " extracting: train/H01_03_bmp_jpg.rf.d91e045eb3748dd5f3940568f5aac8e5.jpg  \n",
            " extracting: train/H01_05_bmp_jpg.rf.9db67d2d6d3a2c2f0d8ec2021273098a.jpg  \n",
            " extracting: train/H01_05_bmp_jpg.rf.bb06babd2019254ed014466c4cf6c392.jpg  \n",
            " extracting: train/H01_05_bmp_jpg.rf.d9dd953c0d4b44246f2f40af483f03b7.jpg  \n",
            " extracting: train/H01_05_bmp_jpg.rf.e597e2c1cf9bcedc8d2ddb48a613456b.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.07991dba69bba4fe7d3c0e8fae8f7628.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.24211933e7663351be2d0c549ed8f4f5.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.30dc41fb8f9307847f20330895cc1b7a.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.391f8e626195f7cc8452ee876594141a.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.55beeeb3270ddea0b0ab1bbc0c9cdd44.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.66d03b15102ccc7bcd0cdf08eefb01bb.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.6fde47a42bf1ba76839dce361e50bb55.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.6fe9d52b8ff1be35176240a64adc8cb8.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.8b94492eafb722b98858d926bcd61787.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.a5ae81a58a231032e809fdc1e62d7c5e.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.d3b0cc6509daad062b67c1d3222c9b59.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.d918aa036dfefb64a31a10c65902a4d7.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.e0f80bbc76290e9467ddeec137c97251.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.e59eb692d16515354f3acbe9065be385.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.ebacb7f4ea5e462e79a050ae88dfbaa7.jpg  \n",
            " extracting: train/H01_07_bmp_jpg.rf.eeaa49caeb2e2aae9cdd001ec0cf0c9f.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.08a60b75e352d251782634866e4ab1d7.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.0b7f28562f9e364ee3adb3dcf3d6392b.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.1d5dcf0f7dba963eb6023a27c3cd3c88.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.4ebabb0fa358f201e4e1aa1994f20b12.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.5c4414f97526a5e5e792e3fb863f2373.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.668cb30e7f49d770b460622b2a339384.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.703da027b1f9f07f250522d948407a35.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.71a81d981732726b5b71436f396370f5.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.a2a0fd2fc73a90678154b5ddae49744a.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.d676909e574fbe6f2ea71c403a5c8cd9.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.e33c19aa6826b1b99097a18e9c93aef9.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.edc9b3c20d7580e3b159a12959b8c164.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.f239783f93ba8ba69fc5130a5e3f006a.jpg  \n",
            " extracting: train/H01_08_bmp_jpg.rf.fd5c74197da13fd26c653ef20609f80d.jpg  \n",
            " extracting: train/H02_02_bmp_jpg.rf.0229b7080fc963d93622d5f2b2357289.jpg  \n",
            " extracting: train/H02_02_bmp_jpg.rf.32659dd1e96f9018d23b4a0a4500b207.jpg  \n",
            " extracting: train/H02_02_bmp_jpg.rf.401d870556759fcc08548edb3a8d5ee4.jpg  \n",
            " extracting: train/H02_02_bmp_jpg.rf.739a3da2cbfe4115c6c1545c335da2a1.jpg  \n",
            " extracting: train/H02_04_bmp_jpg.rf.383e13ecaa0018053e16e7085a06ad4e.jpg  \n",
            " extracting: train/H02_04_bmp_jpg.rf.817d3d3dca0f9c42420bf4361a8775f5.jpg  \n",
            " extracting: train/H02_04_bmp_jpg.rf.823cc52879ffe2eb964d7b655e1f9c73.jpg  \n",
            " extracting: train/H02_04_bmp_jpg.rf.b955407989781ca521b2f35a1611fbd1.jpg  \n",
            " extracting: train/H02_04_bmp_jpg.rf.c702aad84b690435422b9ccc9dade95d.jpg  \n",
            " extracting: train/H02_04_bmp_jpg.rf.eee79fb50df135e88e83ec4f5dbbd855.jpg  \n",
            " extracting: train/H02_05_bmp_jpg.rf.37efb73724c7b528cc8538698df10abf.jpg  \n",
            " extracting: train/H02_05_bmp_jpg.rf.3a3e670233e30fe327acb8bbdc16ce16.jpg  \n",
            " extracting: train/H02_05_bmp_jpg.rf.445aed5df10e7e689ba970025c2a71e1.jpg  \n",
            " extracting: train/H02_05_bmp_jpg.rf.44ef37dc12dbfd831645693d9b278fa7.jpg  \n",
            " extracting: train/H02_05_bmp_jpg.rf.5671ed5fa1e98ce6ef1d5f2225fafabd.jpg  \n",
            " extracting: train/H02_05_bmp_jpg.rf.d3aaa351f7eaa2021db982a6c12f36f6.jpg  \n",
            " extracting: train/H02_06_bmp_jpg.rf.14375bd5abeb59c15d39ee6eb44459e1.jpg  \n",
            " extracting: train/H02_06_bmp_jpg.rf.265cff8a6502669ad043c3a314fe5287.jpg  \n",
            " extracting: train/H02_06_bmp_jpg.rf.28b15fea1d600d704839304d13bdba2e.jpg  \n",
            " extracting: train/H02_06_bmp_jpg.rf.2ac97d2fcf75ca5b478486986bfd767d.jpg  \n",
            " extracting: train/H02_06_bmp_jpg.rf.73db6f5b0e02bc5543dcf951d6b1bb87.jpg  \n",
            " extracting: train/H02_06_bmp_jpg.rf.82849ec3b20c4356669c39b8ded5a44c.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.090ab28d90a37307de36acae2638f2ac.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.0913fbdcccb8dddd970c52eb152bae0f.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.0c48739f7ecc897d7c1e5b8be068b223.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.2cafd73be4dbab1e5b8723579191c4e5.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.7c1f37356329ea49552c98742cc27246.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.91bec00309b9ad1e19950288aaf3cc7c.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.a41706dc8a9c10af8bc7b8abf784a3cd.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.a57267a727141afead8973ba4f2bde4d.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.af26d3de18002b19fe50f75c0df9c208.jpg  \n",
            " extracting: train/H02_08_bmp_jpg.rf.ca053ddfc20e879c13bdb83f6b8fe09b.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.0dcbabbdc4813620806baf7c69f152c2.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.41e9e46607df0c068c1160fd48a0d03a.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.4dddee4c7a8084e891f2040882d6821d.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.97ecffe7d43584ae0107797892dc244f.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.ad3425ba771a479676d889fafe85b40f.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.bc488e18eb0c0b9efdf6b452dcc1a383.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.dbdb2d7b9698e235a396707544beb572.jpg  \n",
            " extracting: train/H02_09_bmp_jpg.rf.e18179e6b3f45a599811fe2d50820b12.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.0cbde8535f10f24020b5a74f8feb4c7f.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.1173e0c958063e1e894c4a7a1e8d6de7.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.1ecc4c02b3adc84dd787c363bd3bc283.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.23cd824f7cb47f53c84f206620cebec8.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.2afb1dda9c8fa85ca6004e6a8c813fdb.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.327048aea4ae5a4b47eed02302ee2c4a.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.33307be45296a8fb892738623aa59e9e.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.592f6a03cf28782471311fd04fbbaed2.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.65b163e500c2c55beba9a09f20e740a6.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.67f4cad386f9315461c726a0df4a6daa.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.68ed13c3fb7ef991f052fb611b16e683.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.806ecab148b16fec52841973ce56885f.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.882da6f274683aa0e7d445b3879c94ce.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.91d96d81ee5066f8530fe8449faedf39.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.aaf776724b66cf6dca3d03bf1459ab75.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.b236dd3fdac9340ce1fc4a6e69ac0b91.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.bb24a3c2f532f2561e157cf120d7034d.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.c07ed0c7795fd14d481cc3ae11cc51ed.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.d42c3c073236a6dbc0bca91a9d9b522a.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.eebb41d1f106a3be100181f9fd6826ab.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.f5406b65d0ae72dc652bab174ed436e8.jpg  \n",
            " extracting: train/H03_02_bmp_jpg.rf.f70821573fe08cc1ac95779dfac2a250.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.086165cbe6a47db7a42b377afbd41ccd.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.1289e5e4c166edcde9baee8337eb54d5.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.17350f8719b4b7c513761b7984ff692a.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.2bd9e7fa2c110dbe58e95f794429af97.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.4def6ae9fcc668728450ef6839697afb.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.50673911acbef441cb23f2e6df123511.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.56df2ec1268ac7fb0d3d73fc3608463e.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.6b49244f92bb49c893ab5a741d7c16cb.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.6d8b7b8c707a93508d612f96995cfadf.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.84cc9a33d0503960907d55bda4ae7d48.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.8aaec2ec05700f10370839043ffd6443.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.961cce14544f911185424092ad8669f7.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.ae92d471e34a3d5a804762b37e59c07a.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.b55e73f4ab8e23a71933388b349fad3f.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.bcf3db406aa1decb25cc159045738d6b.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.cec80697ea0bb87348600105d0c0dfc9.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.e9242e8d6d6d6b4149d35a97773569ad.jpg  \n",
            " extracting: train/H03_03_bmp_jpg.rf.f8eac2a16bb15ecae2be2ea2707e66ef.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.00702323265b676ca81713daa140af44.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.1e04d4f26e4ca965de8901f3f64f1abd.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.22f077b356735850f6c003d7ba0a5e94.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.3540af249213b6acbb55e4956d31a566.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.4289f37c1a18da6c621184905e3f4c2c.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.470f6d89005c9a4e15f855a420e902d6.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.554e32b7872fa9778e7ebbab8aa7ff52.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.7797ee70f4a102264a2984d6065e3545.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.7d31a24dfb36cee06bbee2f419dd7479.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.8108802680193887c7ab9e81aa33d34c.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.9972b19151e08bd9762eab636bfa0c8a.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.b27f25c089e94bddc243b2fdb4a96a59.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.b2985ce3243c24b3cfd06cfeb9c9c8d3.jpg  \n",
            " extracting: train/H03_05_bmp_jpg.rf.cfcf47446aa4be3df3af0dee51c21157.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.1823c8db80758efaa2fd2b7dc86339d0.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.1ddd6c478e23a2b4b04e2c2d6a3f4136.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.24581fcaefb53c7822544ae5d148849d.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.364a95ed61b7fda02fc82327ab6fddc9.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.460f9916dc35a1cee0085449e7c6c76f.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.4ca542a62d3c22d2527ba63b6d1c7575.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.5816e7ec4d508dace8ec6a1d679b91c6.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.58dd2da58114c40ac8606f6c418a1d8f.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.65c31186e871e8000fcf76230fc7ad5a.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.75e6ff8676b95d53ecba3e5ff2b29485.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.8b83e4f17d3448a28077c3144b95082c.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.8dcee9b061b58164515d775451c60d4c.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.b473bd55178059ea0d172a6644983229.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.b4db654d19fca756d125111cb53ac3f5.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.c84d16ab90030ddb8bcbf94d2fd849c9.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.dcebf841add46d620e6410090813e239.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.eff98c44346e1fc7db0d23e060136934.jpg  \n",
            " extracting: train/H03_06_bmp_jpg.rf.f5593fcb08610d005235e4baa2970b78.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.06b405dbc0dd408d0253ffe462fbf935.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.0fb12a73bef57ef79f929335f2c3f958.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.16e24ff8f7c8aa1251333f5448bf6b28.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.42698354b9fdaab604b484e0cbfc6982.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.446aa71b15b95aed99067b655f7a2e86.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.704360e84c405257d98071f2504cc46e.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.762c687f4eeb298e6df048ee691f632f.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.884b5d720d8d9241ece0d66b42fa27b4.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.8dfe7796b90501ecfafe756c85039982.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.998446ac9b66430f267795634438c92b.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.e75525e7b8d2ea95a5109fd134a47cb8.jpg  \n",
            " extracting: train/H03_07_bmp_jpg.rf.ece78861889450edbb6e63ac0583cc1b.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.0b1e8a9ea719f63daed4c8956a5dba3d.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.296532bc13b4103e6c0e2321dcde2963.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.2f859a3daf53f87bbe960904e2fb3edc.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.33d0c0784bbd6c03b67354022f5f400b.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.44ddb0b3f2225b5fce1ed9d1c75709f8.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.53b6f4cbb59bdc2aa515df6e94450388.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.6d6b07edf353a8b170b8d699f45e975e.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.70096b247cc9e609ada5690c1e449437.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.957a10abd1d76d614bf0bf1007924f92.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.98b465b6bd703ab16910ffeed06f6fef.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.b148aa7a213c106c7b3e081d6be137fe.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.d4d03bc3e50063f57db3e9826e33ec2d.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.e345bfa67b550622bde8034808d90957.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.e57d9b96be6aebb6761fa06bf2ba0d59.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.eacfcbf8d2b00a6cdfb97adf541a6814.jpg  \n",
            " extracting: train/H03_08_bmp_jpg.rf.f487185c964262e25ddb8f0a7371cd41.jpg  \n",
            " extracting: train/H03_09_bmp_jpg.rf.270bebd076f82fd5f4a84237ae5566dd.jpg  \n",
            " extracting: train/H03_09_bmp_jpg.rf.2d9dd112ac17c926e50b18e063821f8a.jpg  \n",
            " extracting: train/H03_09_bmp_jpg.rf.5d0074185220aeac970181b7b7486fd9.jpg  \n",
            " extracting: train/H03_09_bmp_jpg.rf.5f3da13e5ee85210f9cda230ac9a5caa.jpg  \n",
            " extracting: train/H03_09_bmp_jpg.rf.aa3ee4d92b7be03e4b3d27a05f856d75.jpg  \n",
            " extracting: train/H03_09_bmp_jpg.rf.dfea7596f6d40ac2fb9b755437b11dbb.jpg  \n",
            " extracting: train/H04_00_bmp_jpg.rf.106cae91bc61dad058a0ca0c3bd0681e.jpg  \n",
            " extracting: train/H04_00_bmp_jpg.rf.7eb9612a0939cc6596b33314bcfc3d4b.jpg  \n",
            " extracting: train/H04_00_bmp_jpg.rf.b58af7ce4f2eb05930335fbd45a7bd73.jpg  \n",
            " extracting: train/H04_00_bmp_jpg.rf.cd34615ee75e5cd1d50513f622ffce99.jpg  \n",
            " extracting: train/H04_01_bmp_jpg.rf.08c5f72d46c6df8b0766a72f325bbaa2.jpg  \n",
            " extracting: train/H04_01_bmp_jpg.rf.6ff19aef897c5ab95c2de61272e912dd.jpg  \n",
            " extracting: train/H04_01_bmp_jpg.rf.a2a8f5049fdc8ce04acb0f5ab643b03e.jpg  \n",
            " extracting: train/H04_01_bmp_jpg.rf.a33fde804cde69f705c99618e04f6501.jpg  \n",
            " extracting: train/H04_01_bmp_jpg.rf.cd3bb9c38882ae826cd2621549b0058a.jpg  \n",
            " extracting: train/H04_01_bmp_jpg.rf.db7fef0f72833617fd2ca76d14cd3db2.jpg  \n",
            " extracting: train/H04_02_bmp_jpg.rf.2f3ca7301f769616aebd68bd5dbc0d97.jpg  \n",
            " extracting: train/H04_02_bmp_jpg.rf.4515cbe2abbddba0e0326bda74124f81.jpg  \n",
            " extracting: train/H04_02_bmp_jpg.rf.6f32b6fc9ca01c45115304538f23ac9a.jpg  \n",
            " extracting: train/H04_02_bmp_jpg.rf.ad6ac6b3ca6560b62f6b368d92a7bb03.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.1e0a17fc998660413e1833355d4e07cd.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.2b3a3f4a962bc05d89041dd67fab63ef.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.3aff33be6bbf212a83629f63592ba4a2.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.40524edf88b7fd7364fcfa92afcc92cf.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.465058f41a843e7b04815b2e8a51942e.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.5721484a494afdc63ff92f6e3962d043.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.8ca1d1fd3a739db0afd1978a29dd2a8d.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.a7ceb3a43667153a76ae31fe74f6dd21.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.ba0ee1008fb37d4e7b4106dd423a446f.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.bbc6ddc8ad23e601956b4a2254637d20.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.c3bb84639785a469234b509fd6068a77.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.c6d7b994c028ef92b98fdd579a358041.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.d0edd53e82a6969f34b3c91d33d919c8.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.d473bfcf8ae680d9c425ab256fb21824.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.f4e3142f343e39c52224f15dc9de1a8f.jpg  \n",
            " extracting: train/H04_04_bmp_jpg.rf.f94d2f2671b7ebde881d179985d771ab.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.01cf8f1c9cc32bb8edf5f4205d4311d5.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.0a6df6c6bef86dadfa35b4b4beae7fdd.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.267d3e9286d9287fdffde1c136c04be0.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.3de68162ae5f367d667db354dd127b2b.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.502cd213aecd000c7e81aab554967cc6.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.50906494d69316c22ecd1c7538d79549.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.66d920a8181a835b74124f28437af098.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.96dede6a3903ddc50b4be1600da25623.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.9cf91a366dd67ac6f4dfd0b5f8e27f67.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.a5530b023e67cd2ea5aeab382f5b5c19.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.a73d39004d80f9415ecbbf52ff9d0c6d.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.b1c09a9c4bf821bd984cfe5d784e18f2.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.b88dec225311a9f72de116145e995fee.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.bf0d8cdd4c3fb0e76377a7ca97a0f683.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.df688a5dab663052c4fb3e68a97dede3.jpg  \n",
            " extracting: train/H04_05_bmp_jpg.rf.e55c7df7e085a3b15ade1581e36b27ad.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.299f71cdef6383f86e31308ba02458c7.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.41ae1ee1fbfe651d9a1a8f0a00b047c9.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.4cf1c061c136b75fd30d7fcfb6c7a1f0.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.55bbfc020f537dc911ac613c7763c30b.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.8aebadc8c7aa426415127d6df1186310.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.990288f941d73cb0a0b40c5a25600cd5.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.a1fc43f55a54db6a44285aa7ab6baf2f.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.b8bbf42981d2cc3962b7543534d073b2.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.d37689a8742a513d14b63af345380352.jpg  \n",
            " extracting: train/H04_06_bmp_jpg.rf.e6b013d30c1a9c12b9fc4342cde1656b.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.159a3c398984793663313ff028dc7c7c.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.1d5f1c1a684a7807394dbb8e55ea2464.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.2884d38d0ad3b51753e901b9e91fbfbc.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.529c2ef42938f178a1136c53e20c63c1.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.70e0c93f37f99e0bd6e39256cad7e723.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.a2949cfdf57b5439d88b8b6561f3a91e.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.b4b68f1366391a39dd258a075c318f66.jpg  \n",
            " extracting: train/H04_08_bmp_jpg.rf.c9ef2147f47c0479f2f5acd6c89eb49e.jpg  \n",
            " extracting: train/_annotations.coco.json  \n"
          ]
        }
      ],
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/UFzKFrkvDS?key=wFV1LglJaf\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI-3zSuCQ9XH"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "register_coco_instances(\"dataset_train\", {}, \"/content/train/_annotations.coco.json\", \"/content/train\")\n",
        "register_coco_instances(\"dataset_test\", {}, \"/content/test/_annotations.coco.json\", \"/content/test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTpXhHrMR-Lu"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3E7a_YZSCTn",
        "outputId": "432aa12b-fc7c-4158-b4ab-5e46069e60fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/10 20:32:43 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 20:32:44 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[03/10 20:32:44 d2.data.datasets.coco]: \u001b[0mLoaded 616 images in COCO format from /content/train/_annotations.coco.json\n",
            "\u001b[32m[03/10 20:32:44 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 616 images left.\n",
            "\u001b[32m[03/10 20:32:44 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
            "\u001b[36m|   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|\n",
            "| Mitotic-cells | 0            |  mitotic   | 855          |\n",
            "|               |              |            |              |\n",
            "|     total     | 855          |            |              |\u001b[0m\n",
            "\u001b[32m[03/10 20:32:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[03/10 20:32:44 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[03/10 20:32:44 d2.data.common]: \u001b[0mSerializing 616 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/10 20:32:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 20:32:44 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "model_final_68b088.pkl: 421MB [00:07, 58.0MB/s]                           \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/10 20:32:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/10 20:35:12 d2.utils.events]: \u001b[0m eta: 2:15:50  iter: 19  total_loss: 1.399  loss_cls: 0.8084  loss_box_reg: 0.3516  loss_rpn_cls: 0.2228  loss_rpn_loc: 0.01102  time: 6.7200  data_time: 0.0352  lr: 0.00015917  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:37:26 d2.utils.events]: \u001b[0m eta: 2:07:35  iter: 39  total_loss: 1.226  loss_cls: 0.4574  loss_box_reg: 0.6904  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.00893  time: 6.6951  data_time: 0.0168  lr: 0.00032567  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:39:43 d2.utils.events]: \u001b[0m eta: 2:17:07  iter: 59  total_loss: 1.063  loss_cls: 0.3441  loss_box_reg: 0.719  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.009893  time: 6.7568  data_time: 0.0168  lr: 0.00049217  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:41:58 d2.utils.events]: \u001b[0m eta: 2:14:51  iter: 79  total_loss: 0.9519  loss_cls: 0.2737  loss_box_reg: 0.6453  loss_rpn_cls: 0.02094  loss_rpn_loc: 0.007836  time: 6.7487  data_time: 0.0157  lr: 0.00065867  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:44:12 d2.utils.events]: \u001b[0m eta: 2:12:27  iter: 99  total_loss: 0.9172  loss_cls: 0.2276  loss_box_reg: 0.6078  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.007872  time: 6.7453  data_time: 0.0189  lr: 0.00082518  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:46:24 d2.utils.events]: \u001b[0m eta: 2:09:40  iter: 119  total_loss: 0.8513  loss_cls: 0.2886  loss_box_reg: 0.5542  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.007145  time: 6.7201  data_time: 0.0158  lr: 0.00099168  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:48:39 d2.utils.events]: \u001b[0m eta: 2:07:15  iter: 139  total_loss: 0.7367  loss_cls: 0.1856  loss_box_reg: 0.5473  loss_rpn_cls: 0.01476  loss_rpn_loc: 0.007519  time: 6.7258  data_time: 0.0151  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:50:56 d2.utils.events]: \u001b[0m eta: 2:04:49  iter: 159  total_loss: 0.7726  loss_cls: 0.212  loss_box_reg: 0.5233  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.007419  time: 6.7397  data_time: 0.0163  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:53:11 d2.utils.events]: \u001b[0m eta: 2:02:16  iter: 179  total_loss: 0.7031  loss_cls: 0.2  loss_box_reg: 0.5202  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.006602  time: 6.7393  data_time: 0.0169  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:55:26 d2.utils.events]: \u001b[0m eta: 1:59:52  iter: 199  total_loss: 0.7302  loss_cls: 0.1961  loss_box_reg: 0.5132  loss_rpn_cls: 0.009609  loss_rpn_loc: 0.005638  time: 6.7398  data_time: 0.0174  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:57:38 d2.utils.events]: \u001b[0m eta: 1:52:48  iter: 219  total_loss: 0.6784  loss_cls: 0.1502  loss_box_reg: 0.5229  loss_rpn_cls: 0.007201  loss_rpn_loc: 0.007804  time: 6.7294  data_time: 0.0154  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 20:59:55 d2.utils.events]: \u001b[0m eta: 1:55:08  iter: 239  total_loss: 0.6037  loss_cls: 0.1436  loss_box_reg: 0.4456  loss_rpn_cls: 0.006087  loss_rpn_loc: 0.006296  time: 6.7389  data_time: 0.0188  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:02:12 d2.utils.events]: \u001b[0m eta: 1:52:46  iter: 259  total_loss: 0.6731  loss_cls: 0.1761  loss_box_reg: 0.4755  loss_rpn_cls: 0.007445  loss_rpn_loc: 0.006632  time: 6.7466  data_time: 0.0153  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:04:25 d2.utils.events]: \u001b[0m eta: 1:50:17  iter: 279  total_loss: 0.6592  loss_cls: 0.1461  loss_box_reg: 0.4885  loss_rpn_cls: 0.006489  loss_rpn_loc: 0.006351  time: 6.7410  data_time: 0.0217  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:06:44 d2.utils.events]: \u001b[0m eta: 1:47:58  iter: 299  total_loss: 0.6842  loss_cls: 0.1451  loss_box_reg: 0.5042  loss_rpn_cls: 0.00747  loss_rpn_loc: 0.007148  time: 6.7534  data_time: 0.0215  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:09:00 d2.utils.events]: \u001b[0m eta: 1:45:31  iter: 319  total_loss: 0.6551  loss_cls: 0.147  loss_box_reg: 0.4464  loss_rpn_cls: 0.006021  loss_rpn_loc: 0.007546  time: 6.7557  data_time: 0.0173  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:11:14 d2.utils.events]: \u001b[0m eta: 1:43:05  iter: 339  total_loss: 0.6524  loss_cls: 0.1742  loss_box_reg: 0.446  loss_rpn_cls: 0.006119  loss_rpn_loc: 0.005768  time: 6.7526  data_time: 0.0191  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:13:34 d2.utils.events]: \u001b[0m eta: 1:40:45  iter: 359  total_loss: 0.6689  loss_cls: 0.1527  loss_box_reg: 0.494  loss_rpn_cls: 0.007398  loss_rpn_loc: 0.006745  time: 6.7671  data_time: 0.0151  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:15:50 d2.utils.events]: \u001b[0m eta: 1:38:20  iter: 379  total_loss: 0.6259  loss_cls: 0.1419  loss_box_reg: 0.4363  loss_rpn_cls: 0.008579  loss_rpn_loc: 0.005939  time: 6.7700  data_time: 0.0162  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:18:04 d2.utils.events]: \u001b[0m eta: 1:35:54  iter: 399  total_loss: 0.6473  loss_cls: 0.1686  loss_box_reg: 0.4705  loss_rpn_cls: 0.005479  loss_rpn_loc: 0.006217  time: 6.7643  data_time: 0.0186  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:20:22 d2.utils.events]: \u001b[0m eta: 1:33:32  iter: 419  total_loss: 0.665  loss_cls: 0.2117  loss_box_reg: 0.422  loss_rpn_cls: 0.007219  loss_rpn_loc: 0.006254  time: 6.7711  data_time: 0.0168  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:22:37 d2.utils.events]: \u001b[0m eta: 1:31:09  iter: 439  total_loss: 0.6827  loss_cls: 0.1886  loss_box_reg: 0.4894  loss_rpn_cls: 0.006431  loss_rpn_loc: 0.007168  time: 6.7714  data_time: 0.0146  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:24:49 d2.utils.events]: \u001b[0m eta: 1:28:44  iter: 459  total_loss: 0.5854  loss_cls: 0.1724  loss_box_reg: 0.4344  loss_rpn_cls: 0.004606  loss_rpn_loc: 0.006733  time: 6.7635  data_time: 0.0172  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:27:05 d2.utils.events]: \u001b[0m eta: 1:26:21  iter: 479  total_loss: 0.6197  loss_cls: 0.1248  loss_box_reg: 0.4678  loss_rpn_cls: 0.005038  loss_rpn_loc: 0.005464  time: 6.7649  data_time: 0.0146  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:29:18 d2.utils.events]: \u001b[0m eta: 1:23:55  iter: 499  total_loss: 0.5952  loss_cls: 0.1387  loss_box_reg: 0.4442  loss_rpn_cls: 0.003049  loss_rpn_loc: 0.00651  time: 6.7592  data_time: 0.0141  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:31:34 d2.utils.events]: \u001b[0m eta: 1:21:31  iter: 519  total_loss: 0.6209  loss_cls: 0.08905  loss_box_reg: 0.4308  loss_rpn_cls: 0.008304  loss_rpn_loc: 0.00557  time: 6.7610  data_time: 0.0164  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:33:52 d2.utils.events]: \u001b[0m eta: 1:19:09  iter: 539  total_loss: 0.681  loss_cls: 0.2052  loss_box_reg: 0.4361  loss_rpn_cls: 0.00637  loss_rpn_loc: 0.006845  time: 6.7667  data_time: 0.0212  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:36:09 d2.utils.events]: \u001b[0m eta: 1:16:45  iter: 559  total_loss: 0.5537  loss_cls: 0.1385  loss_box_reg: 0.4021  loss_rpn_cls: 0.004078  loss_rpn_loc: 0.006055  time: 6.7699  data_time: 0.0182  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:38:27 d2.utils.events]: \u001b[0m eta: 1:14:22  iter: 579  total_loss: 0.595  loss_cls: 0.1204  loss_box_reg: 0.4464  loss_rpn_cls: 0.005079  loss_rpn_loc: 0.005708  time: 6.7746  data_time: 0.0185  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:40:40 d2.utils.events]: \u001b[0m eta: 1:11:57  iter: 599  total_loss: 0.6383  loss_cls: 0.125  loss_box_reg: 0.4556  loss_rpn_cls: 0.0082  loss_rpn_loc: 0.006828  time: 6.7697  data_time: 0.0165  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:42:56 d2.utils.events]: \u001b[0m eta: 1:09:33  iter: 619  total_loss: 0.6552  loss_cls: 0.1607  loss_box_reg: 0.4656  loss_rpn_cls: 0.006222  loss_rpn_loc: 0.005913  time: 6.7715  data_time: 0.0141  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:45:13 d2.utils.events]: \u001b[0m eta: 1:07:09  iter: 639  total_loss: 0.6001  loss_cls: 0.1278  loss_box_reg: 0.3743  loss_rpn_cls: 0.007108  loss_rpn_loc: 0.006108  time: 6.7726  data_time: 0.0180  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:47:28 d2.utils.events]: \u001b[0m eta: 1:04:46  iter: 659  total_loss: 0.5505  loss_cls: 0.142  loss_box_reg: 0.3899  loss_rpn_cls: 0.003672  loss_rpn_loc: 0.007032  time: 6.7727  data_time: 0.0159  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:49:40 d2.utils.events]: \u001b[0m eta: 1:02:21  iter: 679  total_loss: 0.5783  loss_cls: 0.1359  loss_box_reg: 0.4196  loss_rpn_cls: 0.004708  loss_rpn_loc: 0.006352  time: 6.7678  data_time: 0.0156  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:51:55 d2.utils.events]: \u001b[0m eta: 0:59:56  iter: 699  total_loss: 0.6119  loss_cls: 0.1458  loss_box_reg: 0.4283  loss_rpn_cls: 0.002617  loss_rpn_loc: 0.005756  time: 6.7668  data_time: 0.0160  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:54:09 d2.utils.events]: \u001b[0m eta: 0:57:31  iter: 719  total_loss: 0.6054  loss_cls: 0.1876  loss_box_reg: 0.3801  loss_rpn_cls: 0.005904  loss_rpn_loc: 0.005219  time: 6.7648  data_time: 0.0155  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:56:24 d2.utils.events]: \u001b[0m eta: 0:55:08  iter: 739  total_loss: 0.5863  loss_cls: 0.1438  loss_box_reg: 0.404  loss_rpn_cls: 0.004734  loss_rpn_loc: 0.005405  time: 6.7651  data_time: 0.0157  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 21:58:38 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 759  total_loss: 0.5752  loss_cls: 0.1436  loss_box_reg: 0.4357  loss_rpn_cls: 0.006245  loss_rpn_loc: 0.005156  time: 6.7628  data_time: 0.0183  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:00:56 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 779  total_loss: 0.5547  loss_cls: 0.1008  loss_box_reg: 0.4068  loss_rpn_cls: 0.003429  loss_rpn_loc: 0.00554  time: 6.7670  data_time: 0.0179  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:03:11 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 799  total_loss: 0.588  loss_cls: 0.118  loss_box_reg: 0.3909  loss_rpn_cls: 0.003956  loss_rpn_loc: 0.00519  time: 6.7654  data_time: 0.0152  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:05:25 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 819  total_loss: 0.5549  loss_cls: 0.1038  loss_box_reg: 0.4098  loss_rpn_cls: 0.00587  loss_rpn_loc: 0.006564  time: 6.7638  data_time: 0.0175  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:07:42 d2.utils.events]: \u001b[0m eta: 0:43:08  iter: 839  total_loss: 0.5836  loss_cls: 0.137  loss_box_reg: 0.4275  loss_rpn_cls: 0.004961  loss_rpn_loc: 0.005767  time: 6.7668  data_time: 0.0162  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:09:56 d2.utils.events]: \u001b[0m eta: 0:40:44  iter: 859  total_loss: 0.5856  loss_cls: 0.09537  loss_box_reg: 0.4608  loss_rpn_cls: 0.003676  loss_rpn_loc: 0.005809  time: 6.7648  data_time: 0.0186  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:12:12 d2.utils.events]: \u001b[0m eta: 0:38:20  iter: 879  total_loss: 0.568  loss_cls: 0.1454  loss_box_reg: 0.4267  loss_rpn_cls: 0.004441  loss_rpn_loc: 0.004716  time: 6.7653  data_time: 0.0179  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:14:30 d2.utils.events]: \u001b[0m eta: 0:35:56  iter: 899  total_loss: 0.5174  loss_cls: 0.1286  loss_box_reg: 0.38  loss_rpn_cls: 0.002741  loss_rpn_loc: 0.005757  time: 6.7688  data_time: 0.0202  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:16:46 d2.utils.events]: \u001b[0m eta: 0:33:33  iter: 919  total_loss: 0.6228  loss_cls: 0.1188  loss_box_reg: 0.4341  loss_rpn_cls: 0.00297  loss_rpn_loc: 0.005217  time: 6.7689  data_time: 0.0152  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:19:01 d2.utils.events]: \u001b[0m eta: 0:31:09  iter: 939  total_loss: 0.5787  loss_cls: 0.1415  loss_box_reg: 0.3883  loss_rpn_cls: 0.004384  loss_rpn_loc: 0.005652  time: 6.7684  data_time: 0.0163  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:21:19 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 959  total_loss: 0.5307  loss_cls: 0.1249  loss_box_reg: 0.3695  loss_rpn_cls: 0.001733  loss_rpn_loc: 0.006103  time: 6.7720  data_time: 0.0184  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:23:37 d2.utils.events]: \u001b[0m eta: 0:26:22  iter: 979  total_loss: 0.5283  loss_cls: 0.1285  loss_box_reg: 0.4169  loss_rpn_cls: 0.002533  loss_rpn_loc: 0.005659  time: 6.7742  data_time: 0.0168  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:25:56 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 999  total_loss: 0.5646  loss_cls: 0.1224  loss_box_reg: 0.414  loss_rpn_cls: 0.001633  loss_rpn_loc: 0.00638  time: 6.7773  data_time: 0.0159  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:28:12 d2.utils.events]: \u001b[0m eta: 0:21:35  iter: 1019  total_loss: 0.5305  loss_cls: 0.1887  loss_box_reg: 0.3475  loss_rpn_cls: 0.002576  loss_rpn_loc: 0.005127  time: 6.7781  data_time: 0.0172  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:30:28 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 1039  total_loss: 0.5441  loss_cls: 0.1445  loss_box_reg: 0.3747  loss_rpn_cls: 0.004822  loss_rpn_loc: 0.004643  time: 6.7783  data_time: 0.0164  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:32:45 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 1059  total_loss: 0.5798  loss_cls: 0.1255  loss_box_reg: 0.4209  loss_rpn_cls: 0.003322  loss_rpn_loc: 0.005408  time: 6.7800  data_time: 0.0187  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:35:00 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 1079  total_loss: 0.5141  loss_cls: 0.1261  loss_box_reg: 0.3651  loss_rpn_cls: 0.003426  loss_rpn_loc: 0.005391  time: 6.7792  data_time: 0.0180  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:37:15 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 1099  total_loss: 0.5028  loss_cls: 0.125  loss_box_reg: 0.3824  loss_rpn_cls: 0.005405  loss_rpn_loc: 0.006369  time: 6.7785  data_time: 0.0161  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:39:24 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 1119  total_loss: 0.5482  loss_cls: 0.1414  loss_box_reg: 0.3566  loss_rpn_cls: 0.002674  loss_rpn_loc: 0.005665  time: 6.7729  data_time: 0.0174  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:41:42 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 1139  total_loss: 0.5596  loss_cls: 0.1174  loss_box_reg: 0.3908  loss_rpn_cls: 0.003017  loss_rpn_loc: 0.005697  time: 6.7754  data_time: 0.0143  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:43:55 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 1159  total_loss: 0.5437  loss_cls: 0.1334  loss_box_reg: 0.3986  loss_rpn_cls: 0.003448  loss_rpn_loc: 0.005891  time: 6.7731  data_time: 0.0167  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:46:10 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 1179  total_loss: 0.5491  loss_cls: 0.1267  loss_box_reg: 0.372  loss_rpn_cls: 0.00362  loss_rpn_loc: 0.005225  time: 6.7720  data_time: 0.0165  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:48:26 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1199  total_loss: 0.48  loss_cls: 0.1191  loss_box_reg: 0.3442  loss_rpn_cls: 0.003678  loss_rpn_loc: 0.004959  time: 6.7716  data_time: 0.0160  lr: 0.001  max_mem: 8668M\n",
            "\u001b[32m[03/10 22:48:26 d2.engine.hooks]: \u001b[0mOverall training speed: 1198 iterations in 2:15:12 (6.7716 s / it)\n",
            "\u001b[32m[03/10 22:48:26 d2.engine.hooks]: \u001b[0mTotal training time: 2:15:15 (0:00:02 on hooks)\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 22:48:27 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[03/10 22:48:27 d2.data.datasets.coco]: \u001b[0mLoaded 616 images in COCO format from /content/train/_annotations.coco.json\n",
            "\u001b[32m[03/10 22:48:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[03/10 22:48:27 d2.data.common]: \u001b[0mSerializing 616 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/10 22:48:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 22:48:27 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[03/10 22:48:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 616 batches\n",
            "\u001b[32m[03/10 22:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/616. Dataloading: 0.0018 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0921 s/iter. ETA=0:11:00\n",
            "\u001b[32m[03/10 22:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 16/616. Dataloading: 0.0023 s/iter. Inference: 1.0914 s/iter. Eval: 0.0003 s/iter. Total: 1.0942 s/iter. ETA=0:10:56\n",
            "\u001b[32m[03/10 22:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 21/616. Dataloading: 0.0025 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0933 s/iter. ETA=0:10:50\n",
            "\u001b[32m[03/10 22:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 26/616. Dataloading: 0.0025 s/iter. Inference: 1.0904 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:10:45\n",
            "\u001b[32m[03/10 22:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 31/616. Dataloading: 0.0026 s/iter. Inference: 1.0905 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:10:39\n",
            "\u001b[32m[03/10 22:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 36/616. Dataloading: 0.0027 s/iter. Inference: 1.0905 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:10:34\n",
            "\u001b[32m[03/10 22:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 41/616. Dataloading: 0.0029 s/iter. Inference: 1.0908 s/iter. Eval: 0.0003 s/iter. Total: 1.0944 s/iter. ETA=0:10:29\n",
            "\u001b[32m[03/10 22:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 46/616. Dataloading: 0.0028 s/iter. Inference: 1.0908 s/iter. Eval: 0.0003 s/iter. Total: 1.0943 s/iter. ETA=0:10:23\n",
            "\u001b[32m[03/10 22:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 51/616. Dataloading: 0.0029 s/iter. Inference: 1.0905 s/iter. Eval: 0.0003 s/iter. Total: 1.0942 s/iter. ETA=0:10:18\n",
            "\u001b[32m[03/10 22:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 56/616. Dataloading: 0.0028 s/iter. Inference: 1.0904 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:10:12\n",
            "\u001b[32m[03/10 22:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 61/616. Dataloading: 0.0030 s/iter. Inference: 1.0907 s/iter. Eval: 0.0003 s/iter. Total: 1.0944 s/iter. ETA=0:10:07\n",
            "\u001b[32m[03/10 22:49:39 d2.evaluation.evaluator]: \u001b[0mInference done 66/616. Dataloading: 0.0030 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0941 s/iter. ETA=0:10:01\n",
            "\u001b[32m[03/10 22:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 71/616. Dataloading: 0.0030 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:09:56\n",
            "\u001b[32m[03/10 22:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 76/616. Dataloading: 0.0029 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:09:50\n",
            "\u001b[32m[03/10 22:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 81/616. Dataloading: 0.0029 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:09:45\n",
            "\u001b[32m[03/10 22:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 86/616. Dataloading: 0.0029 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:09:39\n",
            "\u001b[32m[03/10 22:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 91/616. Dataloading: 0.0028 s/iter. Inference: 1.0897 s/iter. Eval: 0.0003 s/iter. Total: 1.0934 s/iter. ETA=0:09:34\n",
            "\u001b[32m[03/10 22:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 96/616. Dataloading: 0.0027 s/iter. Inference: 1.0896 s/iter. Eval: 0.0003 s/iter. Total: 1.0933 s/iter. ETA=0:09:28\n",
            "\u001b[32m[03/10 22:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 101/616. Dataloading: 0.0027 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:09:23\n",
            "\u001b[32m[03/10 22:50:23 d2.evaluation.evaluator]: \u001b[0mInference done 106/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:09:17\n",
            "\u001b[32m[03/10 22:50:28 d2.evaluation.evaluator]: \u001b[0mInference done 111/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:09:12\n",
            "\u001b[32m[03/10 22:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 116/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:09:06\n",
            "\u001b[32m[03/10 22:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 121/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:09:01\n",
            "\u001b[32m[03/10 22:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 126/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:08:55\n",
            "\u001b[32m[03/10 22:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 131/616. Dataloading: 0.0028 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:08:50\n",
            "\u001b[32m[03/10 22:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 136/616. Dataloading: 0.0028 s/iter. Inference: 1.0897 s/iter. Eval: 0.0003 s/iter. Total: 1.0934 s/iter. ETA=0:08:44\n",
            "\u001b[32m[03/10 22:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 141/616. Dataloading: 0.0028 s/iter. Inference: 1.0896 s/iter. Eval: 0.0003 s/iter. Total: 1.0933 s/iter. ETA=0:08:39\n",
            "\u001b[32m[03/10 22:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 146/616. Dataloading: 0.0027 s/iter. Inference: 1.0896 s/iter. Eval: 0.0003 s/iter. Total: 1.0933 s/iter. ETA=0:08:33\n",
            "\u001b[32m[03/10 22:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 151/616. Dataloading: 0.0027 s/iter. Inference: 1.0897 s/iter. Eval: 0.0003 s/iter. Total: 1.0933 s/iter. ETA=0:08:28\n",
            "\u001b[32m[03/10 22:51:18 d2.evaluation.evaluator]: \u001b[0mInference done 156/616. Dataloading: 0.0028 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:08:23\n",
            "\u001b[32m[03/10 22:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 161/616. Dataloading: 0.0028 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:08:17\n",
            "\u001b[32m[03/10 22:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 166/616. Dataloading: 0.0028 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:08:12\n",
            "\u001b[32m[03/10 22:51:34 d2.evaluation.evaluator]: \u001b[0mInference done 171/616. Dataloading: 0.0028 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:08:06\n",
            "\u001b[32m[03/10 22:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 176/616. Dataloading: 0.0028 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:08:01\n",
            "\u001b[32m[03/10 22:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 181/616. Dataloading: 0.0027 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:07:55\n",
            "\u001b[32m[03/10 22:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 186/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:07:50\n",
            "\u001b[32m[03/10 22:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 191/616. Dataloading: 0.0027 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:07:44\n",
            "\u001b[32m[03/10 22:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 196/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:07:39\n",
            "\u001b[32m[03/10 22:52:07 d2.evaluation.evaluator]: \u001b[0mInference done 201/616. Dataloading: 0.0027 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:07:33\n",
            "\u001b[32m[03/10 22:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 206/616. Dataloading: 0.0028 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:07:28\n",
            "\u001b[32m[03/10 22:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 211/616. Dataloading: 0.0028 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:07:22\n",
            "\u001b[32m[03/10 22:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 216/616. Dataloading: 0.0028 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:07:17\n",
            "\u001b[32m[03/10 22:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 221/616. Dataloading: 0.0028 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:07:12\n",
            "\u001b[32m[03/10 22:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 226/616. Dataloading: 0.0028 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:07:06\n",
            "\u001b[32m[03/10 22:52:40 d2.evaluation.evaluator]: \u001b[0mInference done 231/616. Dataloading: 0.0028 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:07:01\n",
            "\u001b[32m[03/10 22:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 236/616. Dataloading: 0.0027 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:06:55\n",
            "\u001b[32m[03/10 22:52:51 d2.evaluation.evaluator]: \u001b[0mInference done 241/616. Dataloading: 0.0027 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:06:50\n",
            "\u001b[32m[03/10 22:52:56 d2.evaluation.evaluator]: \u001b[0mInference done 246/616. Dataloading: 0.0027 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:06:44\n",
            "\u001b[32m[03/10 22:53:01 d2.evaluation.evaluator]: \u001b[0mInference done 251/616. Dataloading: 0.0027 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:06:39\n",
            "\u001b[32m[03/10 22:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 256/616. Dataloading: 0.0027 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:06:33\n",
            "\u001b[32m[03/10 22:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 261/616. Dataloading: 0.0027 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:06:28\n",
            "\u001b[32m[03/10 22:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 266/616. Dataloading: 0.0028 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:06:22\n",
            "\u001b[32m[03/10 22:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 271/616. Dataloading: 0.0027 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:06:17\n",
            "\u001b[32m[03/10 22:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 276/616. Dataloading: 0.0027 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:06:11\n",
            "\u001b[32m[03/10 22:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 281/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:06:06\n",
            "\u001b[32m[03/10 22:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 286/616. Dataloading: 0.0028 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:06:01\n",
            "\u001b[32m[03/10 22:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 291/616. Dataloading: 0.0028 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:55\n",
            "\u001b[32m[03/10 22:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 296/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:50\n",
            "\u001b[32m[03/10 22:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 301/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:44\n",
            "\u001b[32m[03/10 22:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 306/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:39\n",
            "\u001b[32m[03/10 22:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 311/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0941 s/iter. ETA=0:05:33\n",
            "\u001b[32m[03/10 22:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 316/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:28\n",
            "\u001b[32m[03/10 22:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 321/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:22\n",
            "\u001b[32m[03/10 22:54:24 d2.evaluation.evaluator]: \u001b[0mInference done 326/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:17\n",
            "\u001b[32m[03/10 22:54:29 d2.evaluation.evaluator]: \u001b[0mInference done 331/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:11\n",
            "\u001b[32m[03/10 22:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 336/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:06\n",
            "\u001b[32m[03/10 22:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 341/616. Dataloading: 0.0028 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:05:00\n",
            "\u001b[32m[03/10 22:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 346/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:04:55\n",
            "\u001b[32m[03/10 22:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 351/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:04:49\n",
            "\u001b[32m[03/10 22:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 356/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:04:44\n",
            "\u001b[32m[03/10 22:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 361/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:04:38\n",
            "\u001b[32m[03/10 22:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 366/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:04:33\n",
            "\u001b[32m[03/10 22:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 371/616. Dataloading: 0.0027 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:04:28\n",
            "\u001b[32m[03/10 22:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 376/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:04:22\n",
            "\u001b[32m[03/10 22:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 381/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:04:17\n",
            "\u001b[32m[03/10 22:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 386/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:04:11\n",
            "\u001b[32m[03/10 22:55:35 d2.evaluation.evaluator]: \u001b[0mInference done 391/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:04:06\n",
            "\u001b[32m[03/10 22:55:40 d2.evaluation.evaluator]: \u001b[0mInference done 396/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:04:00\n",
            "\u001b[32m[03/10 22:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 401/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:03:55\n",
            "\u001b[32m[03/10 22:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 406/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:03:49\n",
            "\u001b[32m[03/10 22:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 411/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:03:44\n",
            "\u001b[32m[03/10 22:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 416/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:03:38\n",
            "\u001b[32m[03/10 22:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 421/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:03:33\n",
            "\u001b[32m[03/10 22:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 426/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:03:27\n",
            "\u001b[32m[03/10 22:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 431/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:03:22\n",
            "\u001b[32m[03/10 22:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 436/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0940 s/iter. ETA=0:03:16\n",
            "\u001b[32m[03/10 22:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 441/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:03:11\n",
            "\u001b[32m[03/10 22:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 446/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:03:05\n",
            "\u001b[32m[03/10 22:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 451/616. Dataloading: 0.0026 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:03:00\n",
            "\u001b[32m[03/10 22:56:46 d2.evaluation.evaluator]: \u001b[0mInference done 456/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:02:55\n",
            "\u001b[32m[03/10 22:56:51 d2.evaluation.evaluator]: \u001b[0mInference done 461/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:02:49\n",
            "\u001b[32m[03/10 22:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 466/616. Dataloading: 0.0026 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:02:44\n",
            "\u001b[32m[03/10 22:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 471/616. Dataloading: 0.0027 s/iter. Inference: 1.0903 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:02:38\n",
            "\u001b[32m[03/10 22:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 476/616. Dataloading: 0.0027 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:02:33\n",
            "\u001b[32m[03/10 22:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 481/616. Dataloading: 0.0027 s/iter. Inference: 1.0902 s/iter. Eval: 0.0003 s/iter. Total: 1.0938 s/iter. ETA=0:02:27\n",
            "\u001b[32m[03/10 22:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 486/616. Dataloading: 0.0026 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:02:22\n",
            "\u001b[32m[03/10 22:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 491/616. Dataloading: 0.0026 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:02:16\n",
            "\u001b[32m[03/10 22:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 496/616. Dataloading: 0.0026 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0937 s/iter. ETA=0:02:11\n",
            "\u001b[32m[03/10 22:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 501/616. Dataloading: 0.0026 s/iter. Inference: 1.0901 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:02:05\n",
            "\u001b[32m[03/10 22:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 506/616. Dataloading: 0.0026 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0936 s/iter. ETA=0:02:00\n",
            "\u001b[32m[03/10 22:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 511/616. Dataloading: 0.0026 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:01:54\n",
            "\u001b[32m[03/10 22:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 516/616. Dataloading: 0.0026 s/iter. Inference: 1.0900 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:01:49\n",
            "\u001b[32m[03/10 22:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 521/616. Dataloading: 0.0026 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0935 s/iter. ETA=0:01:43\n",
            "\u001b[32m[03/10 22:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 526/616. Dataloading: 0.0026 s/iter. Inference: 1.0899 s/iter. Eval: 0.0003 s/iter. Total: 1.0934 s/iter. ETA=0:01:38\n",
            "\u001b[32m[03/10 22:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 531/616. Dataloading: 0.0026 s/iter. Inference: 1.0898 s/iter. Eval: 0.0003 s/iter. Total: 1.0934 s/iter. ETA=0:01:32\n",
            "\u001b[32m[03/10 22:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 536/616. Dataloading: 0.0026 s/iter. Inference: 1.0897 s/iter. Eval: 0.0003 s/iter. Total: 1.0933 s/iter. ETA=0:01:27\n",
            "\u001b[32m[03/10 22:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 541/616. Dataloading: 0.0026 s/iter. Inference: 1.0897 s/iter. Eval: 0.0003 s/iter. Total: 1.0932 s/iter. ETA=0:01:21\n",
            "\u001b[32m[03/10 22:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 546/616. Dataloading: 0.0026 s/iter. Inference: 1.0896 s/iter. Eval: 0.0003 s/iter. Total: 1.0932 s/iter. ETA=0:01:16\n",
            "\u001b[32m[03/10 22:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 551/616. Dataloading: 0.0026 s/iter. Inference: 1.0897 s/iter. Eval: 0.0003 s/iter. Total: 1.0932 s/iter. ETA=0:01:11\n",
            "\u001b[32m[03/10 22:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 556/616. Dataloading: 0.0026 s/iter. Inference: 1.0896 s/iter. Eval: 0.0003 s/iter. Total: 1.0932 s/iter. ETA=0:01:05\n",
            "\u001b[32m[03/10 22:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 561/616. Dataloading: 0.0026 s/iter. Inference: 1.0896 s/iter. Eval: 0.0003 s/iter. Total: 1.0932 s/iter. ETA=0:01:00\n",
            "\u001b[32m[03/10 22:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 566/616. Dataloading: 0.0026 s/iter. Inference: 1.0896 s/iter. Eval: 0.0003 s/iter. Total: 1.0931 s/iter. ETA=0:00:54\n",
            "\u001b[32m[03/10 22:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 571/616. Dataloading: 0.0026 s/iter. Inference: 1.0895 s/iter. Eval: 0.0003 s/iter. Total: 1.0931 s/iter. ETA=0:00:49\n",
            "\u001b[32m[03/10 22:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 576/616. Dataloading: 0.0026 s/iter. Inference: 1.0895 s/iter. Eval: 0.0003 s/iter. Total: 1.0931 s/iter. ETA=0:00:43\n",
            "\u001b[32m[03/10 22:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 581/616. Dataloading: 0.0026 s/iter. Inference: 1.0895 s/iter. Eval: 0.0003 s/iter. Total: 1.0930 s/iter. ETA=0:00:38\n",
            "\u001b[32m[03/10 22:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 586/616. Dataloading: 0.0026 s/iter. Inference: 1.0894 s/iter. Eval: 0.0003 s/iter. Total: 1.0930 s/iter. ETA=0:00:32\n",
            "\u001b[32m[03/10 22:59:13 d2.evaluation.evaluator]: \u001b[0mInference done 591/616. Dataloading: 0.0026 s/iter. Inference: 1.0894 s/iter. Eval: 0.0003 s/iter. Total: 1.0930 s/iter. ETA=0:00:27\n",
            "\u001b[32m[03/10 22:59:18 d2.evaluation.evaluator]: \u001b[0mInference done 596/616. Dataloading: 0.0026 s/iter. Inference: 1.0893 s/iter. Eval: 0.0003 s/iter. Total: 1.0929 s/iter. ETA=0:00:21\n",
            "\u001b[32m[03/10 22:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 601/616. Dataloading: 0.0026 s/iter. Inference: 1.0893 s/iter. Eval: 0.0003 s/iter. Total: 1.0929 s/iter. ETA=0:00:16\n",
            "\u001b[32m[03/10 22:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 606/616. Dataloading: 0.0026 s/iter. Inference: 1.0892 s/iter. Eval: 0.0003 s/iter. Total: 1.0928 s/iter. ETA=0:00:10\n",
            "\u001b[32m[03/10 22:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 611/616. Dataloading: 0.0026 s/iter. Inference: 1.0892 s/iter. Eval: 0.0003 s/iter. Total: 1.0928 s/iter. ETA=0:00:05\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 616/616. Dataloading: 0.0026 s/iter. Inference: 1.0892 s/iter. Eval: 0.0003 s/iter. Total: 1.0927 s/iter. ETA=0:00:00\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:11:07.782727 (1.092934 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:11:05 (1.089195 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.890\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
            "| 43.968 | 88.977 | 34.607 | 28.314 | 45.953 |  nan  |\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP   | category   | AP     |\n",
            "|:--------------|:-----|:-----------|:-------|\n",
            "| Mitotic-cells | nan  | mitotic    | 43.968 |\n",
            "\u001b[32m[03/10 22:59:40 d2.engine.defaults]: \u001b[0mEvaluation results for dataset_train in csv format:\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/10 22:59:40 d2.evaluation.testing]: \u001b[0mcopypaste: 43.9678,88.9769,34.6068,28.3143,45.9534,nan\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"dataset_train\",)\n",
        "cfg.DATASETS.TEST  = (\"dataset_train\",)\n",
        "#cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "#cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Projects/Final Year Project/Saved_Model [512 x 512 Epochs-500]/model_final.pth\"\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "\n",
        "cfg.SOLVER.WARMUP_ITERS = 120\n",
        "cfg.SOLVER.MAX_ITER = 1200 #adjust up if val mAP is still rising, adjust down if overfit\n",
        "# cfg.SOLVER.STEPS = []\n",
        "cfg.SOLVER.GAMMA = 0.05\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 5\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2 #your number of classes + 1\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmOerG8idEfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9568ef2-42c5-4649-d036-c44d63cc07a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 23:00:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 23:00:40 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[03/10 23:00:40 d2.data.datasets.coco]: \u001b[0mLoaded 153 images in COCO format from /content/test/_annotations.coco.json\n",
            "\u001b[32m[03/10 23:00:40 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
            "\u001b[36m|   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|\n",
            "| Mitotic-cells | 0            |  mitotic   | 216          |\n",
            "|               |              |            |              |\n",
            "|     total     | 216          |            |              |\u001b[0m\n",
            "\u001b[32m[03/10 23:00:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[03/10 23:00:40 d2.data.common]: \u001b[0mSerializing 153 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/10 23:00:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[03/10 23:00:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 153 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/10 23:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/153. Dataloading: 0.0017 s/iter. Inference: 1.0884 s/iter. Eval: 0.0003 s/iter. Total: 1.0904 s/iter. ETA=0:02:34\n",
            "\u001b[32m[03/10 23:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 16/153. Dataloading: 0.0020 s/iter. Inference: 1.0895 s/iter. Eval: 0.0003 s/iter. Total: 1.0920 s/iter. ETA=0:02:29\n",
            "\u001b[32m[03/10 23:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 21/153. Dataloading: 0.0023 s/iter. Inference: 1.0910 s/iter. Eval: 0.0003 s/iter. Total: 1.0939 s/iter. ETA=0:02:24\n",
            "\u001b[32m[03/10 23:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 26/153. Dataloading: 0.0025 s/iter. Inference: 1.0895 s/iter. Eval: 0.0003 s/iter. Total: 1.0926 s/iter. ETA=0:02:18\n",
            "\u001b[32m[03/10 23:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 31/153. Dataloading: 0.0027 s/iter. Inference: 1.0895 s/iter. Eval: 0.0003 s/iter. Total: 1.0929 s/iter. ETA=0:02:13\n",
            "\u001b[32m[03/10 23:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 36/153. Dataloading: 0.0029 s/iter. Inference: 1.0895 s/iter. Eval: 0.0003 s/iter. Total: 1.0930 s/iter. ETA=0:02:07\n",
            "\u001b[32m[03/10 23:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 41/153. Dataloading: 0.0028 s/iter. Inference: 1.0894 s/iter. Eval: 0.0003 s/iter. Total: 1.0929 s/iter. ETA=0:02:02\n",
            "\u001b[32m[03/10 23:01:30 d2.evaluation.evaluator]: \u001b[0mInference done 46/153. Dataloading: 0.0028 s/iter. Inference: 1.0893 s/iter. Eval: 0.0003 s/iter. Total: 1.0928 s/iter. ETA=0:01:56\n",
            "\u001b[32m[03/10 23:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 51/153. Dataloading: 0.0027 s/iter. Inference: 1.0891 s/iter. Eval: 0.0003 s/iter. Total: 1.0924 s/iter. ETA=0:01:51\n",
            "\u001b[32m[03/10 23:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 56/153. Dataloading: 0.0027 s/iter. Inference: 1.0893 s/iter. Eval: 0.0003 s/iter. Total: 1.0926 s/iter. ETA=0:01:45\n",
            "\u001b[32m[03/10 23:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 61/153. Dataloading: 0.0028 s/iter. Inference: 1.0890 s/iter. Eval: 0.0003 s/iter. Total: 1.0925 s/iter. ETA=0:01:40\n",
            "\u001b[32m[03/10 23:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 66/153. Dataloading: 0.0028 s/iter. Inference: 1.0892 s/iter. Eval: 0.0003 s/iter. Total: 1.0929 s/iter. ETA=0:01:35\n",
            "\u001b[32m[03/10 23:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 71/153. Dataloading: 0.0028 s/iter. Inference: 1.0891 s/iter. Eval: 0.0003 s/iter. Total: 1.0927 s/iter. ETA=0:01:29\n",
            "\u001b[32m[03/10 23:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 76/153. Dataloading: 0.0030 s/iter. Inference: 1.0888 s/iter. Eval: 0.0003 s/iter. Total: 1.0926 s/iter. ETA=0:01:24\n",
            "\u001b[32m[03/10 23:02:09 d2.evaluation.evaluator]: \u001b[0mInference done 81/153. Dataloading: 0.0030 s/iter. Inference: 1.0887 s/iter. Eval: 0.0003 s/iter. Total: 1.0925 s/iter. ETA=0:01:18\n",
            "\u001b[32m[03/10 23:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 86/153. Dataloading: 0.0030 s/iter. Inference: 1.0886 s/iter. Eval: 0.0003 s/iter. Total: 1.0924 s/iter. ETA=0:01:13\n",
            "\u001b[32m[03/10 23:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 91/153. Dataloading: 0.0029 s/iter. Inference: 1.0885 s/iter. Eval: 0.0003 s/iter. Total: 1.0923 s/iter. ETA=0:01:07\n",
            "\u001b[32m[03/10 23:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 96/153. Dataloading: 0.0029 s/iter. Inference: 1.0884 s/iter. Eval: 0.0003 s/iter. Total: 1.0921 s/iter. ETA=0:01:02\n",
            "\u001b[32m[03/10 23:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 101/153. Dataloading: 0.0030 s/iter. Inference: 1.0881 s/iter. Eval: 0.0003 s/iter. Total: 1.0919 s/iter. ETA=0:00:56\n",
            "\u001b[32m[03/10 23:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 106/153. Dataloading: 0.0030 s/iter. Inference: 1.0881 s/iter. Eval: 0.0003 s/iter. Total: 1.0919 s/iter. ETA=0:00:51\n",
            "\u001b[32m[03/10 23:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 111/153. Dataloading: 0.0030 s/iter. Inference: 1.0880 s/iter. Eval: 0.0003 s/iter. Total: 1.0918 s/iter. ETA=0:00:45\n",
            "\u001b[32m[03/10 23:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 116/153. Dataloading: 0.0029 s/iter. Inference: 1.0879 s/iter. Eval: 0.0003 s/iter. Total: 1.0917 s/iter. ETA=0:00:40\n",
            "\u001b[32m[03/10 23:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 121/153. Dataloading: 0.0030 s/iter. Inference: 1.0878 s/iter. Eval: 0.0003 s/iter. Total: 1.0916 s/iter. ETA=0:00:34\n",
            "\u001b[32m[03/10 23:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 126/153. Dataloading: 0.0030 s/iter. Inference: 1.0878 s/iter. Eval: 0.0003 s/iter. Total: 1.0917 s/iter. ETA=0:00:29\n",
            "\u001b[32m[03/10 23:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 131/153. Dataloading: 0.0030 s/iter. Inference: 1.0878 s/iter. Eval: 0.0003 s/iter. Total: 1.0917 s/iter. ETA=0:00:24\n",
            "\u001b[32m[03/10 23:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 136/153. Dataloading: 0.0031 s/iter. Inference: 1.0877 s/iter. Eval: 0.0003 s/iter. Total: 1.0916 s/iter. ETA=0:00:18\n",
            "\u001b[32m[03/10 23:03:14 d2.evaluation.evaluator]: \u001b[0mInference done 141/153. Dataloading: 0.0030 s/iter. Inference: 1.0880 s/iter. Eval: 0.0003 s/iter. Total: 1.0919 s/iter. ETA=0:00:13\n",
            "\u001b[32m[03/10 23:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 146/153. Dataloading: 0.0030 s/iter. Inference: 1.0881 s/iter. Eval: 0.0003 s/iter. Total: 1.0919 s/iter. ETA=0:00:07\n",
            "\u001b[32m[03/10 23:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 151/153. Dataloading: 0.0030 s/iter. Inference: 1.0881 s/iter. Eval: 0.0003 s/iter. Total: 1.0918 s/iter. ETA=0:00:02\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:41.684717 (1.092464 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:41 (1.088077 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
            "| 34.869 | 74.492 | 22.020 | 8.284 | 37.518 |  nan  |\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[03/10 23:03:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP   | category   | AP     |\n",
            "|:--------------|:-----|:-----------|:-------|\n",
            "| Mitotic-cells | nan  | mitotic    | 34.869 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 34.86920482326941,\n",
              "               'AP-Mitotic-cells': nan,\n",
              "               'AP-mitotic': 34.86920482326941,\n",
              "               'AP50': 74.49233671631,\n",
              "               'AP75': 22.019871723020728,\n",
              "               'APl': nan,\n",
              "               'APm': 37.51756386648014,\n",
              "               'APs': 8.284307470781913})])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"dataset_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"dataset_test\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final Year Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}